# 美团推出 LongCat-Flash-Lite；字节跳动发布 Seedance 2.0【AI 早报 2026-02-07】

- status: captured
- source_url: manual_paste_in_chat
- source_type: user_paste
- note: 用户在对话中提供全文，原文层按全文保真归档（不做摘要压缩）。

Image
AI 早报 2026-02-07

## 概览

### 精选
美团推出LongCat-Flash-Lite模型 #1
字节跳动发布视频生成模型 Seedance 2.0 #2
OpenRouter与Kilo Code上线 Pony Alpha 模型 #3

### 模型发布
Waymo推出Waymo World Model #4

### 开发生态
X开发者平台上线API按量计费及xAI联动 #5

### 产品应用
OpenAI开放Sora真人角色视频生成功能 #6
Perplexity推出多模型聚合问答功能 #7

### 行业动态
中科曙光启用超三万卡国产AI算力池 #8

### 技术与洞察
OpenAI推动内部转向Agent开发模式 #9

### 前瞻与传闻
OpenAI 将于今年推出AI硬件 Dime 智能耳机 #10
面壁智能推出首款AI硬件松果派 #11

## 详细条目（全文）

### 美团推出LongCat-Flash-Lite模型 #1
美团龙猫团队发布并开源了 LongCat-Flash-Lite 模型，参数总量 685 亿，推理时仅激活 29 亿至 45 亿，采用 N-gram 嵌入 与 专用缓存优化，生成速度达 500 至 700 token/s。该模型已开源权重。开发者可申请 API 接入，每日享 5000 万 tokens 免费额度。

美团龙猫团队推出 LongCat-Flash-Lite 大模型，这是一款采用全新嵌入扩展范式的轻量化 MoE 模型。该模型总参数量为 685 亿，通过动态激活机制，每次推理仅需激活 29 亿至 45 亿 参数。LongCat-Flash-Lite 聚焦于 Agent 与代码领域，支持基于 YARN 技术的 256K 超长上下文处理，目前已开放模型权重、推理引擎部分源代码及 API 接入服务。

在架构设计上，该模型创新性地引入了 N-gram 嵌入层，将 31.4 亿 参数（约占 46%）投入到嵌入扩展中。该设计通过哈希函数将 token 序列映射为整体嵌入向量，并采用子表分解等技术降低哈希冲突。同时，模型引入嵌入放大技术，确保信号在深层网络中有效传递。

系统级优化方面，团队实现了从模型结构到运行时的垂直加速。针对 N-gram 嵌入层特性，设计了专用的 GPU 缓存机制以降低延迟。在算子层面，开发了定制 CUDA 内核并进行内核融合，同时支持 3 步投机推理。在输入 4K、输出 1K 的典型负载下，其 API 生成速度可达 500-700 token/s。

性能评估显示，LongCat-Flash-Lite 在多项基准测试中表现优异。在智能体任务 τ²-Bench 中取得高分，代码任务 SWE-Bench 准确率为 54.4%。通用能力方面，MMLU 得分 85.52，中文理解 C-Eval 为 86.55 分，数学能力 MATH500 准确率达 96.80%。

目前，LongCat-Flash-Lite 模型权重已在 Hugging Face 与 Modelscope 开放下载，推理引擎部分功能与算子在 GitHub 开源。开发者可通过 API 平台申请接入，现阶段提供不限额试用，后续将维持每日 5000 万 tokens 的免费额度。

Image
https://mp.weixin.qq.com/s/-MCo9-FV7afO3ydqmAHY9Q
https://huggingface.co/meituan-longcat/LongCat-Flash-Lite
https://github.com/meituan-longcat/SGLang-FluentLLM

### 字节跳动发布视频生成模型 Seedance 2.0 #2
字节跳动发布视频生成模型 Seedance 2.0，支持图像、视频、音频、文本四模态输入，可生成 4至15秒 视频。核心功能为「参考能力」，支持通过参考图还原构图细节，参考视频复刻镜头与动作节奏，并支持视频延长、衔接、角色更替等编辑操作。

Seedance  2.0  正式上线，推出支持图像、视频、音频、文本四种模态输入的视频生成功能。其核心特性「参考能力」允许用户上传参考图像以还原画面构图与角色细节，或通过参考视频复刻镜头语言、动作节奏与创意特效。系统支持对生成视频进行平滑延长、衔接以及角色更替、内容增删等编辑操作，生成长度可在 4 至 15 秒间自由配置。

在输入限制方面，系统规定混合输入总上限为 12 个文件，包括不超过 9 张图像、总时长不超过 15 秒的 3 个视频，以及总时长不超过 15 秒的 3 个 MP3 格式音频文件。文本输入则采用自然语言描述，输出视频默认自带音效与配乐。

系统提供「首尾帧」与「全能参考」两种交互入口。「首尾帧」适用于仅需上传首帧图结合提示词的简单场景；「全能参考」则支持四类素材的任意组合输入。在「全能参考」模式下，用户可通过 @素材名 语法指定素材用途，或通过参数工具栏的 @ 图标唤起选单。需要注意的是，智能多帧与主体参考功能在当前版本不可用。

在能力提升方面，Seedance 2.0 攻克了物理规律合理性、动作自然流畅性、指令理解精准度及风格稳定性等难题，能稳定完成复杂动作与连续运动生成任务，并在人脸、服装、字体及场景细节一致性上实现了显著提升。

Image
https://bytedance.larkoffice.com/wiki/A5RHwWhoBiOnjukIIw6cu5ybnXQ

### OpenRouter与Kilo Code上线 Pony Alpha 模型 #3
OpenRouter 与 Kilo Code 同步上线了 stealth 模型 Pony Alpha，该模型被描述为擅长 编码、推理 与 角色扮演，当前免费开放测试。有未经证实的观点认为该模型是 智谱AI 即将发布的 GLM-5 模型。

OpenRouter 与 Kilo Code 同步上线了 stealth 模型 Pony Alpha，定位为支持 coding、agentic workflows 与 reasoning 的下一代基础模型。该模型提供 200K tokens 上下文窗口与 131K tokens 最大输出，通过两家平台以零费率提供。

模型来源暂未正式披露，Kilo Code 将其描述为来自“global lab”的“beloved open-source models”的 specialized evolution。对此，部分讨论认为该模型或为智谱（zAI）即将发布的 GLM-5，但此说法未经官方证实。

Image
https://openrouter.ai/openrouter/pony-alpha
https://blog.kilo.ai/p/announcing-a-deep-thinking-new-stealth

### Waymo推出Waymo World Model #4
Waymo 推出基于 Google DeepMind Genie 3 的 Waymo World Model，用于自动驾驶仿真。该模型可生成高保真多模态数据，支持自然语言、驾驶输入和场景布局控制，将真实视频转为仿真环境。已用于数十亿英里虚拟训练。

Waymo推出Waymo World Model，基于Google DeepMind的Genie 3构建，用于大规模超真实自动驾驶仿真。该系统生成高保真、多传感器输出，同步包含camera图像与lidar点云，支持通过自然语言、驾驶输入及场景布局调整进行精细控制。Waymo Driver已积累近2亿英里全自动驾驶里程，并在此模型驱动的虚拟世界中完成数十亿英里训练，以在实际道路遭遇前掌握复杂罕见场景。

Image
https://waymo.com/blog/2026/02/the-waymo-world-model-a-new-frontier-for-autonomous-driving-simulation

### X开发者平台上线API按量计费及xAI联动 #5
X Developer Platform 上线 API按量付费 模式，面向开发者及初创团队开放。原免费用户将自动迁移，并获 10美元 代金券支持。平台同步推出 xAI积分奖励机制，消费达标可获 10%至20% 积分返还，需绑定 xAI团队。

X Developer Platform正式上线X API Pay-Per-Use计费模式，取代原有免费层级，面向开发者与初创团队开放。原Legacy Free用户将自动迁移至新模式并获赠10美元代金券；Basic与Pro固定套餐仍保留，用户可自主选择。公益性公共事业应用继续免费。平台同步推出xAI API积分联动机制：开发者购买X API积分后，按计费周期累积消费额度获相应比例免费xAI API积分返还，需预先在X开发者账户设置中绑定xAI team。

https://developer.x.com
https://x.com/XDevelopers/status/2019881223666233717

### OpenAI开放Sora真人角色视频生成功能 #6
OpenAI 更新 Sora 模型，支持用户上传真实人物照片生成视频，并可创建个性化角色。功能上线需获得肖像权与版权授权，内容审核更严格。

OpenAI 视频模型 Sora 更新，支持基于真实人物图像生成视频和创建 Character 角色。其 Image to Video 功能支持上传人物照片作起点，Characters 功能（原 Sora Cameos）允许上传相识者照片创建个性化角色。新功能上线伴随更严格审核，要求用户上传人物图像前，须确获肖像权人同意与媒体版权。

Image
https://help.openai.com/en/articles/12593142-sora-release-notes#image-2-video-with-people
https://x.com/AndrewCurran_/status/2019772046130258095

### Perplexity推出多模型聚合问答功能 #7
Perplexity 推出 Model Council 功能，支持用户单次查询调用多个前沿 AI 模型 并获取综合答案。该功能仅面向 Perplexity Max 订阅用户，在网页版可用。

Perplexity 推出 Model Council 功能，支持单次查询并行调用多个前沿模型并生成综合答案。该功能通过 合成器模型 整合 Claude Opus 4.6、GPT 5.2 及 Gemini 3.0 等模型的输出，自动标注一致性与分歧区域并生成共识表。据转述的使用案例显示，系统可单次执行 55 个步骤的并行研究任务。功能适用于投资研究、复杂决策评估、创意头脑风暴和信息验证等场景。目前仅向 Perplexity Max 订阅用户开放网页版访问权限，移动端支持待后续更新提供。

Image
https://www.perplexity.ai/hub/blog/introducing-model-council

### 中科曙光启用超三万卡国产AI算力池 #8
中科曙光在郑州上线三套万卡超集群，建成全国首个超 3万卡 国产 AI 算力池，已投入运营。

中科曙光于 2026年2月5日 在国家超算互联网郑州核心节点建成全国首个超 3万卡 国产AI算力池，试运行 3套scaleX 万卡集群。系统采用自研 scaleFabric 高速网络，基于国内首款 400G 类 InfiniBand RDMA 网卡，带宽达 400Gb/s，延迟低于 1微秒，性能提升超 2倍，成本降低约 30%。硬件方面为全球首创高密度机柜，采用浸没相变液冷技术，算力密度提升约 20倍，PUE 低至 1.04。运维层引入数字孪生技术，智能调度引擎支持每秒万级作业，系统可用性达 99.99%。软件兼容 CUDA，支持多品牌加速卡混合部署，已适配 400 余个主流大模型。

https://zhidx.com/p/533695.html

### OpenAI推动内部转向Agent开发模式 #9
OpenAI 总裁 Greg Brockman 发文称，Codex 能力显著提升，已能编写大部分代码并承担运维调试任务。OpenAI 计划在 3 月 31 日前，推动 Agent 成为工程师首选交互方式，取代传统编辑器与终端。

OpenAI 总裁 Greg Brockman 发文，阐述公司正推动内部团队向以 Agent 为核心（Agentic）的软件开发模式转型。基于自 12月 以来 Codex 能力的阶梯式提升，其应用范围已从单元测试扩展至覆盖几乎所有代码编写、运维及调试工作。因此，OpenAI 计划在 3月31日 前，使 Agent 成为工程师处理任何技术任务的首选工具，以取代传统的编辑器或终端交互模式。

为支撑这一开发范式，OpenAI 正在实施制度化变革。在团队层面，需任命“Agents Captain”负责引入流程，并指定频道分享经验。在技术与文档规范上，每个项目必须创建 AGENTS.md 文件，用于记录 Agent 处理任务时的错误与困境，工程师则需将 Codex 实现的功能封装为 Skills 并提交至共享仓库。开发流程也相应转向编写可快速运行的测试与构建高质量接口。

为保障 AI 生成代码的质量，人类开发者仍对所有合并代码承担最终责任，代码审查标准须维持与人类编写代码时同等的水准。在基础架构层面，各团队需梳理依赖工具清单，确保其通过 CLI 或 MCP server 实现 Agent 可访问性，并优化可观测性，以追踪 Agent 操作轨迹。

https://x.com/gdb/status/2019566641491963946

### OpenAI 将于今年推出AI硬件 Dime 智能耳机 #10
据爆料，OpenAI 将于今年推出命名为 Dime 的智能耳机，由 Jony Ive 参与设计，定位为 AirPod 竞品。

OpenAI 将推出其首款硬件设备——由 Jony Ive 参与设计的智能耳机 Dime（内部代号 Sweetpea），旨在作为 AirPods 的竞争产品实现耳边 ChatGPT 交互。根据爆料，OpenAI 已采取分阶段发布策略，计划于 2026 年优先交付结构简单的基础音频版本，而集成高性能计算的进阶型号则因供应链成本因素推迟发布。

进阶版原计划搭载 2nm 工艺芯片以实现“类手机”计算能力，对 HBM（高带宽存储器）有极高要求。据社媒转述的供应链线索，由于 HBM 持续短缺，导致该型号的物料清单（BOM）成本大幅超出预期，这促使高级 SKU 的生产确认延迟。OpenAI 计划待元器件成本改善后再推出该版本。

https://x.com/zhihuipikachu/status/2019811756487708970
https://x.com/kimmonismus/status/2019844845334905307
https://x.com/chetaslua/status/2019840530067444158

### 面壁智能推出首款AI硬件松果派 #11
面壁智能发布首款AI开发板松果派，基于 NVIDIA Jetson 模组，支持离线多模态运行，集成 MiniCPM-V 与 MiniCPM-o 模型，实现“看听我说”全栈开发。该产品预计年中量产上市，具体售价待定。

面壁智能推出首款AI硬件产品松果派（Pinea Pi），这是一款面向端侧智能开发的AI原生（AI Native）开发板。产品基于NVIDIA Jetson系列模组构建，内置麦克风、摄像头及丰富外设接口，预装面壁智能自研的MiniCPM-V与MiniCPM-o多模态模型并支持全链路离线运行。该产品定位为零门槛端侧Agent开发平台，覆盖离线多模态个人知识助理、具身智能、编程教具等场景的全栈开发，预期于年中正式量产上市，当前售价未定。

Image
https://mp.weixin.qq.com/s/maqPObOAu6COKkBPUOeyWQ
提示：内容由AI辅助创作，可能存在幻觉和错误。

作者橘鸦Juya，视频版在同名哔哩哔哩。欢迎点赞、关注、分享。

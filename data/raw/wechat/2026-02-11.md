# 千问发布Qwen-Image-2.0图像模型【AI 早报 2026-02-11】

- status: captured
- source_url: https://mp.weixin.qq.com/s/ZWc2EsB4jcGbPeCf7gRZSA
- source_type: user_paste
- note: 用户在对话中提供全文，原文层按全文保真归档（不做摘要压缩）。

Image
AI 早报 2026-02-11

## 概览

### 精选
- 千问推出Qwen-Image-2.0统一图像模型 #1

### 模型发布
- MOSI.AI与OpenMOSS发布MOSS-TTS家族 #2
- 蚂蚁集团发布LLaDA2.1扩散大语言模型 #3
- 腾讯混元发布HY-1.8B-2Bit端侧量化模型 #4

### 开发生态
- OpenAI 将高风险 GPT-5.3-Codex 请求路由至 GPT-5.2 #5
- OpenAI更新Responses API支持Agent任务 #6
- Claude Code Desktop引入YOLO模式 #7
- Warp推出Oz云原生Agent编排平台 #8
- Antigravity 向 Pro 账户提供 Claude Opus 4.6 #9
- Gemini 发布 Gemini API skills #10
- Entire成立并获6000万美元种子融资 #11
- draw.io发布官方MCP服务器 #12

### 产品应用
- Anthropic发布Windows版Claude Cowork #13
- Claude App更新交互回复，开放语音模式 #14
- OpenAI更新ChatGPT Deep Research至GPT-5.2 #15
- Google Stitch推出Figma设计导出功能 #16
- Obsidian发布Obsidian CLI #17

### 行业动态
- 豆包上线与央视春晚联名新年活动 #18
- Runway完成3.15亿美元E轮融资 #19
- Nebius收购Tavily #20

### 技术与洞察
- Anthropic发布2026 Agent编程趋势报告 #21
- Unsloth发布MoE训练优化 #22
- Chrome 146 推出 WebMCP 早期预览 #23

### 前瞻与传闻
- Gemini 正开发 Premium Content 功能 #24

## 详细条目（全文）

### 千问推出Qwen-Image-2.0统一图像模型 #1
千问大模型团队发布新一代图像生成模型 Qwen-Image-2.0，该模型统一生成与编辑能力，具备专业文字渲染、真实质感表现等优势，已在阿里云百炼平台开放 API，用户可通过 Qwen Chat 免费体验，即将上线 千问 App。

千问大模型团队推出新一代图像生成基础模型Qwen-Image-2.0。该模型统一了图像生成与编辑能力，支持2K分辨率输出与1k token超长指令输入。目前已在阿里云百炼平台开放API，并可通过Qwen Chat免费体验。

Qwen-Image-2.0的核心能力集中在专业文字渲染、真实质感表现与语义遵循。文字渲染方面，可精准处理中英双语信息图，并支持1k token复杂指令。模型原生支持2048×2048分辨率，可刻画超23种绿色植被的材质与光影，并在多介质上维持文字真实感。同时，模型可生成多子图漫画，保持角色一致性。

作为统一的Omni模型，其编辑功能支持在图片上添加书法题词、生成九宫格多姿势组图与双人自然合成，还可在保持真实照片主体的前提下添加卡通形象，并支持指定等效镜头与光圈等参数。

技术架构上，Qwen-Image-2.0由8B Qwen3-VL编码器与7B扩散解码器组成，体积较前代20B模型显著减小，推理更快。团队通过提升VAE重构能力与增强密集小字建模，解决了文字渲染崩坏问题，而生图与编辑的训练也相互促进。

据AI Arena盲测基准，Qwen-Image-2.0文生图得分1029排名第三，图片编辑得分1034排名第二。对比测试显示，其在长指令遵循与文字渲染上优于部分竞品，但在超现实场景的真实感上略逊一筹。

模型当前仅通过API提供，权重未开源，有传言称或于春节后开源。

Image
Image
https://qwen.ai/blog?id=qwen-image-2.0
https://chat.qwen.ai
https://mp.weixin.qq.com/s/D8nwRYxQp7wv9yzfk8FL9A

### MOSI.AI与OpenMOSS发布MOSS-TTS家族 #2
MOSI.AI 与 OpenMOSS 团队联合发布开源语音模型家族 MOSS-TTS，包含五个生产级模型，支持高保真语音生成、多说话人对话、音色设计与环境音效，采用 Apache-2.0 许可证。

MOSI.AI 与 OpenMOSS 团队将于2026年2月10日发布开源语音与声音生成模型家族MOSS-TTS，采用Apache-2.0许可证。该家族设计面向高保真、高表现力及复杂真实世界场景，包含五个可独立或组合使用的生产级模型。

该家族由五大核心模型构成：

旗舰MOSS-TTS 提供MossTTSDelay（8B参数，侧重长上下文稳定与速度）和MossTTSLocal（1.7B参数，侧重轻量化）两种架构，支持高保真零样本克隆与长文本生成；
MOSS-TTSD v1.0

专用于生成高表现力的多说话人超长连续对话；

MOSS-VoiceGenerator

可直接从文本指令生成多样化音色；

MOSS-TTS-Realtime

是为实时语音智能体设计的多轮上下文感知模型；

MOSS-SoundEffect

则专用于内容创作的可控音效生成。

整个家族的性能基于统一的1.6B参数MOSS-Audio-Tokenizer。该组件基于Cat架构，在300万小时音频数据上训练，能将24kHz音频高效压缩至12.5Hz，其重建质量在可比较比特率范围内据评测领先于其他开源方案。

性能方面，在开源基准Seed-TTS-eval上，MossTTSLocal 的英文词错误率（WER）与中文相似度（SIM）分别为 1.85% 和 78.82%。MOSS-TTSD v1.0 的中文说话人相似度（SIM）达 0.7949，切换准确率（ACC）为 0.9587，主观评测中其综合表现优于Doubao及Gemini 2.5-pro等部分闭源模型。

Image
https://github.com/OpenMOSS/MOSS-TTS
https://huggingface.co/collections/OpenMOSS-Team/moss-tts
https://mosi.cn/models/moss-tts

### 蚂蚁集团发布LLaDA2.1扩散大语言模型 #3
蚂蚁集团发布 LLaDA2.1 扩散大语言模型，含 16B 与 100B 两个版本，采用 Token-to-Token 编辑机制，支持实时纠错。LLaDA2.1-Flash 推理速度达 892 tokens/sec，性能优于同类模型。

蚂蚁集团推出名为 LLaDA2.1 的扩散大语言模型，提供 16B 参数的 Mini 和 100B 参数的 Flash 两个版本。该模型核心是集成 Error-Correcting Editable (ECE) 引擎的 Token-to-Token 编辑机制，区别于传统自回归方式。该机制允许模型在生成中实时修正 token。

LLaDA2.1-Flash 为 100B 参数的语言扩散 MoE 模型，根据官方信息，这是首个应用于 100B 参数量级扩散模型的大规模 强化学习 (RL) 框架。性能方面，在复杂编码任务中，LLaDA2.1-Flash 推理速度可达 892 tokens/sec。

目前，LLaDA2.1 的模型权重、技术报告与源代码已发布在 HuggingFace 和 GitHub 上。

Image
Image
https://github.com/inclusionAI/LLaDA2.X
https://huggingface.co/collections/inclusionAI/llada21

### 腾讯混元发布HY-1.8B-2Bit端侧量化模型 #4
腾讯混元推出 HY-1.8B-2Bit 模型，该模型基于 Hunyuan-1.8B-Instruct，采用 2比特量化感知训练，使生成速度提升 2至3倍，同时保留了思维链推理能力。

腾讯混元推出面向消费级硬件的 HY-1.8B-2Bit 模型，该方案基于产业级 2Bit端侧量化技术。模型通过对 Hunyuan-1.8B-Instruct 进行量化感知训练（QAT）产出，等效参数量为 0.3B，内存占用 600MB，文件大小仅 300MB。在真实端侧设备上，其生成速度相较原始精度模型提升 2至3倍，并完整保留了其全思维链推理能力及 Dual-CoT 策略。该模型目前已开源，适配支持 Arm SME2 技术的计算平台。

技术上，为避免传统后量化（PTQ）在低比特量化下的严重精度损失，混元团队采用了 量化感知训练（QAT），并结合数据优化、弹性拉伸量化及训练策略创新提升模型能力。基准测试显示，与全精度 1.8B 教师模型相比，HY-1.8B-2Bit 在八个主流数据集上的平均性能下降 3.97%；与 INT4 量化版本相比，准确率差距仅 0.13%。在与空间相当的 0.5B 模型对比中，该模型在 GSM8K 和 LiveCodeBench 数据集上分别高出 22.29% 和 20.62%。

在真实设备测试中，HY-1.8B-2Bit 在 MacBook M4 上，对比 fp16 及 Q4 格式，首字时延实现 3至8倍加速，生成速度稳定提升超 2倍。在 天玑9500 芯片上，对比 Q4 格式，首字时延与生成速度均实现约 1.5倍 的加速。

该模型当前部署存在明确限制，仅支持配备 Arm SME2 技术的设备，如 Apple M4、vivo x300 等，其依赖于 llama.cpp 的特定分支运行。模型能力亦受限于其监督微调（SFT）的训练流程与基础模型自身性能。项目代码及权重已开源，采用 License for AngelSlim。未来团队将重点发展 强化学习 与 模型蒸馏，以缩小低比特模型与全精度模型的能力差距。

Image
https://huggingface.co/AngelSlim/HY-1.8B-2Bit
https://mp.weixin.qq.com/s/m3Sr4fRLAvc7C6MV1RR-ew

### OpenAI 将高风险 GPT-5.3-Codex 请求路由至 GPT-5.2 #5
OpenAI 被发现将部分 GPT-5.3-Codex 请求路由至 GPT-5.2，工作人员称滥用风险升高时会部分请求将自动转至 GPT-5.2 模型，正优化检测模型，并计划增加路由状态通知。

OpenAI 被发现将部分 GPT-5.3-Codex 请求路由至 GPT-5.2，Codex 工作人员称这是作为降低网络滥用风险的措施。当系统检测到滥用风险升高时，用户发起的部分请求可能会被自动路由至模型 GPT-5.2。

Codex 工作人员表示正在对检测系统进行持续调优，并计划在未来版本中增加清晰的路由状态通知。对于被误判的防御性研究用户，可申请恢复访问。

Image
http://chatgpt.com/cyber
https://openai.com
https://github.com/openai
https://openai.com/blog
https://huggingface.co/openai
https://x.com/embirico/status/2021376881942200801

### OpenAI更新Responses API支持Agent任务 #6
OpenAI 更新 Responses API，新增 服务端压缩 以 延长运行时长，支持 网络访问的托管容器，并原生集成 Agent Skills 标准，首发 spreadsheets skill。

OpenAI 在 Responses API 中新增三项功能，支持长时间 agentic 任务：

服务端压缩功能，可扩展运行时长至数小时；
为托管容器提供受控网络访问，支持安装库和运行脚本；
原生支持 Agent Skills 标准，并推出首个预构建的 spreadsheets skill。
Image
https://developers.openai.com/api/docs/guides/tools-shell…
https://x.com/OpenAIDevs/status/2021286050623373500

### Claude Code Desktop引入YOLO模式 #7
Claude Code Desktop 新增 --dangerously-skip-permissions 参数，该功能需谨慎使用，存在数据丢失等风险。

Claude Code Desktop 引入了参数 --dangerously-skip-permissions，允许在可信环境中跳过所有权限提示，以实现完全自主、无中断的工作流。该参数使用时需保持谨慎。其风险真实存在，可能导致数据丢失。

Image
https://x.com/lydiahallie/status/2021012074160324633

### Warp推出Oz云原生Agent编排平台 #8
Warp 推出云原生平台 Oz，支持大规模运行和编排编码 Agent。用户可通过 CLI、API、SDK 或 Web 界面启动 Agent，支持自动化任务和 Skill 调用。

Warp 推出名为 Oz 的云原生平台，用于大规模运行、管理和编排编码 Agent。该平台支持用户并行启动云代理处理复杂开发任务、自动化如功能标志清理和文档更新等重复性工作，并构建基于 Agent 的应用程序，如错误分类和事件响应系统。Oz 提供 Agent 自动追踪与审计功能，并支持通过 CLI 和 API 控制。

https://www.warp.dev/blog/oz-orchestration-platform-cloud-agents
https://oz.warp.dev/

### Antigravity 向 Pro 账户提供 Claude Opus 4.6 #9
Google AI Pro 用户现已可在 Antigravity 中使用 Claude Opus 4.6 模型。

Google AI Pro 用户现已可在 Antigravity 中使用 Claude Opus 4.6 模型。

Image
https://linux.do/t/topic/1589167

### Gemini 发布 Gemini API skills #10
Google Gemini 在 GitHub 开源了名为 gemini-skills 的技能库，用于增强 Gemini API 与 SDK 的交互能力。

Google 在 GitHub 发布了一个名为 gemini-skills 的开源代码库，采用 Apache-2.0 许可证。该技能库旨在为开发者提供与 Gemini API、SDK 及模型交互的实践指南，其中包含的 gemini-api-dev 技能为构建 Gemini 驱动型应用提供了最佳实践。项目声明明确指出，这并非 Google 官方支持的产品。

Image
https://github.com/google-gemini/gemini-skills

### Entire成立并获6000万美元种子融资 #11
前 GitHub CEO Thomas Dohmke 创立 Entire 公司，获 6000万美元 种子融资，估值 3亿美元。其首款产品是一款开源 CLI 工具，核心功能是将 AI Agent 会话集成至 Git 工作流。

前GitHub CEO Thomas Dohmke 创立的新开发者平台公司 Entire 宣布成立，并完成由 Felicis 领投的 6000万美元 种子轮融资，估值达 3亿美元。其平台旨在为 AI agents 与人类提供开放、可扩展的协作环境。

首款产品为开源 CLI 工具 Checkpoints，它通过钩入 Git 工作流，在代码提交时捕获 AI agent 的会话内容、上下文及推理过程，形成可搜索记录。该工具目前支持 Anthropic 的 Claude Code 和 Google 的 Gemini CLI。

Entire CLI 的核心在于将 AI 会话 作为版本化数据集成到 Git 中。它通过独立分支存储会话元数据，保持代码历史的整洁，并允许用户通过如 rewind 和 resume 等命令管理会话状态。

工具的核心概念是 Session（一次完整的 AI 交互）和 Checkpoint（Session 内的快照），提供 manual-commit（在 git commit 时创建）和 auto-commit（在 agent 响应后自动创建）两种策略。它兼容 Git worktrees，并能独立跟踪同一提交上的多个并发 AI 会话。Entire CLI 采用 MIT 许可证 开源。

Image
https://github.com/entireio/cli
https://entire.io/blog/hello-entire-world

### draw.io发布官方MCP服务器 #12
draw.io 发布了官方 MCP 服务器 @drawio/mcp，支持 LLM 在编辑器中创建和打开图表。

draw.io 发布官方 MCP 服务器@drawio/mcp，使 LLM 能直接生成图表。

核心功能包括三大工具：

open_drawio_xml

：处理原生 XML 格式；

open_drawio_csv

：转换表格数据；

open_drawio_mermaid

：支持 Mermaid 语法，均支持 URL 读取。

https://x.com/drawio/status/2020918870375370825

### Anthropic发布Windows版Claude Cowork #13
Anthropic 推出适用于 Windows 的 Claude Cowork，功能与 macOS 版本一致，支持文件访问、多步骤任务、插件及 MCP 连接器等功能。

Anthropic正式发布Windows版Claude Cowork，功能与macOS版本完全对等。核心能力包括：文件访问（读写本地文件）、多步骤任务执行（处理复杂连贯任务）、插件支持（扩展Agent能力）及MCP连接器（集成外部工具与数据源）。新增全局和文件夹级指令功能，将在每个会话中自动生效。该版本目前处于research preview阶段，已向所有付费Claude计划订阅用户开放访问权限，可通过官方网站获取。

Image
https://x.com/claudeai/status/2021336313979625910

### Claude App更新交互回复，开放语音模式 #14
Claude 应用更新，新增交互式回复功能，用户可点击地图组件和选择器与内容互动，同时有报道称语音模式正分阶段向更多用户开放。

Claude app近日更新，引入全新交互式回复功能，允许用户通过点击方式与生成内容进行互动。该功能突破了此前的纯文本输出限制，在保留传统文本交互的同时，新增了地图组件和新选择器等交互元素，用于特定场景下的直接操作。

此外，据社媒转述，一个全新的语音模式正处于分阶段推广中，正向更多用户开放。另有社媒消息称，部分设计细节是直接通过代码实现的。

Image
https://x.com/jenny_wen/status/2021242950139650209

### OpenAI更新ChatGPT Deep Research至GPT-5.2 #15
OpenAI 已将 ChatGPT 的 Deep Research 功能基础模型升级至 GPT-5.2 模型，并支持用户连接应用、搜索特定网站，实时追踪与干预研究过程。该功能正分阶段推出。

OpenAI 为 ChatGPT 的 Deep Research 功能推出更新，将其底层模型升级至 GPT-5.2，并增强了交互与报告能力，目前该功能正分阶段向用户推出。

本次更新新增多项核心能力：用户可连接 ChatGPT 内部应用，并指定搜索特定网站或域名，以实现精准的信息源定位；界面支持对研究进度的实时可视化跟踪，并允许用户在过程中输入追问或提供新信息来中断及调整研究方向；最终生成的研究报告新增全屏查看模式以优化阅读。

Image
https://x.com/OpenAI/status/2021299935678026168

### Google Stitch推出Figma设计导出功能 #16
Google Stitch 推出新功能，支持将设计直接导出为 Figma 可编辑图层。用户可通过 Export 或右键 Copy to Figma 实现无缝迁移。

Google Stitch 推出 Figma 导出功能，可将 agent 生成设计转为可编辑图层。用户可通过 Export→Figma 或右键 Copy to Figma 后粘贴实现。Redesign Agent（由 Nano Banana Pro 驱动）生成的设计需先 Convert to Code 再导出。

Image
https://x.com/stitchbygoogle/status/2021320125983621626

### Obsidian发布Obsidian CLI #17
Obsidian 推出 Obsidian CLI 命令行工具，支持脚本化控制与自动化。支持单命令与交互式终端模式。可执行搜索、创建笔记、管理任务等操作，并提供开发者调试命令。

Obsidian 推出名为 Obsidian CLI 的 Early Access 命令行工具，需 Catalyst license 和 1.12+ 版本。支持单命令执行和交互式终端界面（TUI）两种模式，可实现文件管理、搜索、任务、标签、每日笔记等几乎所有应用功能。含开发者专用命令：插件重载、执行 JavaScript、截图、调试等。

Image
https://help.obsidian.md/cli
https://x.com/obsdmd/status/2021241384057930224

### 豆包上线与央视春晚联名新年活动 #18
豆包携手央视春晚推出“豆包过年”活动，2月16日除夕当晚将派发超10万份含豆包大模型的科技好礼及最高8888元现金红包。

豆包与春晚合作，推出“豆包过年”新春活动。活动已在App上线，提供AI生成新春写真、拜年视频等玩法。用户自2月13日晚8点起可参与抽奖，除夕当晚（2月16日）将派发超10万份接入豆包大模型的科技好礼及最高8888元现金红包。

本次派发的科技好礼共计17种，均为接入豆包大模型的前沿智能产品，包括机器人、无人机、3D打印机、智能手表及两款电车的使用权。

Image
https://mp.weixin.qq.com/s/LXa1fUQTsjxQuPWITE9oQw

### Runway完成3.15亿美元E轮融资 #19
Runway 公司完成 3.15亿美元 E轮融资，估值达到 53亿美元。融资资金将主要用于开发下一代 世界模型 和推出新产品。

Runway 完成了一轮 3.15亿美元 的 E系列轮融资，公司估值近乎翻倍至 53亿美元。据一位知情人士透露，此笔资金将遵循公司规划，重点用于预训练下一代 世界模型，并将其引入新产品及行业应用中。

https://techcrunch.com/2026/02/10/ai-video-startup-runway-raises-315m-at-5-3b-valuation-eyes-more-capable-world-models

### Nebius收购Tavily #20
Nebius announced the acquisition of agentic search provider Tavily, aimed at boosting its AI platform’s real-time web verification capabilities. The deal is expected to close within a few weeks.

Nebius 已达成协议收购 agentic search 提供商 Tavily，将其功能整合至 AI云平台。交易预计数周内完成，金额未披露，Tavily 团队将加入 Nebius 并继续独立运营。此次收购结合 Nebius Token Factory 的高性能推理与 Tavily 的实时网络验证，为 autonomous AI agents 构建核心基础设施。

Image
https://nebius.com/newsroom/nebius-announces-agreement-to-acquire-tavily-to-add-agentic-search-to-its-ai-cloud-platform

### Anthropic发布2026 Agent编程趋势报告 #21
Anthropie 发布《2026 Agent编程趋势报告》，预测软件开发将经历重大变革。工程师角色将转向 Agent 编排者，多Agent协同 与 长时间自主运行 成主流。

Anthropic 发布了一份《2026 Agent 编程趋势报告》，该报告提出了八项预测。报告的核心观点指出，软件开发生命周期将发生巨变，工程师的角色将从编码者转型为 Agent 编排者，多 Agent 协同 和 长时间自主运行 将成为重要趋势。报告同时回顾了 2025 年 编程 Agent 从实验性工具演进为可交付功能的生产系统的过程，AI 已能处理包括编写测试、调试、生成文档及在复杂代码库中导航在内的完整开发工作流。

Image
https://resources.anthropic.com/hubfs/2026%20Agentic%20Coding%20Trends%20Report.pdf?hsLang=en
https://mp.weixin.qq.com/s/zRe0r2gTYu0c8nl0rLMvIQ

### Unsloth发布MoE训练优化 #22
Unsloth 更新了其代码库，通过使用自定义的 Triton 内核与 torch._grouped_mm 进行优化，实现了对 MoE 模型训练速度 提升 12 倍以上，并实现了 VRAM 节省超过 35%，上下文长度扩展约 6 倍。

Unsloth 更新代码仓库，为 Mixture of Experts (MoE) 模型训练引入优化，实现相比 transformers v4 约 12 倍的训练速度、超过 35% 的 VRAM 节省以及约 6 倍的上下文长度扩展，且不损失精度。

Image
https://unsloth.ai/docs/new/faster-moe

### Chrome 146 推出 WebMCP 早期预览 #23
Chrome 146 推出 WebMCP 早期预览，这是一种开放标准，允许 AI Agent 直接调用网站服务，无需模拟用户操作。开发者可通过 API 或 表单 声明功能，目前需启用 flag 使用。

Chrome 146 版本引入了对 WebMCP（Model Context Protocol for Web）的早期预览支持，这是一个使 AI Agent 能够直接查询和执行网站服务，而无需模拟用户浏览的开放标准。该功能目前处于实验阶段，用户需通过启用浏览器 flag 才能访问。

WebMCP 允许网站服务主动、预先地声明其能力，使 AI Agent 可绕过用户界面直接访问站点函数，从而提升效率和可靠性。

Image
https://docs.google.com/document/d/1rtU1fRPS0bMqd9abMG_hc6K9OAI6soUy3Kh00toAgyk/edit
https://t.co/UaUplZ8Q28

### Gemini 正开发 Premium Content 功能 #24
Google 正在开发名为 Premium Content 的功能，让 Gemini 优先使用用户付费订阅的内容生成答案。用户可通过界面控制是否启用 《华尔街日报》、《经济学人》 等来源，目前该功能仍在开发中。

Google 正在为其 AI 模型 Gemini 开发一项名为“Premium Content”的新功能。该功能旨在优先利用用户已付费订阅的内容来生成更高质量的回答。根据功能界面展示，用户将能通过总开关启用或禁用此功能，并可对《纽约时报》、《华尔街日报》等特定订阅源进行精细化控制，精确调整 Gemini 生成回应时所引用的内容来源。目前，该功能仍处于开发阶段。

Image
https://x.com/testingcatalog/status/2021356522853531949

提示：内容由AI辅助创作，可能存在幻觉和错误。

作者橘鸦Juya，视频版在同名哔哩哔哩。欢迎点赞、关注、分享。

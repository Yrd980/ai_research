candidate_id,subject_entity_id,subject_text,predicate,object_type,object_value,event_date,event_title,event_summary,source_url,source_type,status,last_updated,quote_span,raw_file,item_no,notes
C00001,cmp_google,Google,daily_report_fact,text,Gemini正在测试从ChatGPT等平台导入对话历史的功能,2026-02-01,Gemini正在测试从ChatGPT等平台导入对话历史的功能,Google 测试 Gemini 对话导入、图像下载分辨率与相关新功能。,https://www.testingcatalog.com/google-will-make-it-easier-to-import-chatgpt-conversations-to-gemini/,primary,candidate,2026-02-12,Google 测试 Gemini 对话导入、图像下载分辨率与相关新功能。,data/raw/wechat/2026-02-01.md,1,from_ai_daily_primary_link
C00002,cmp_anthropic,Anthropic,daily_report_fact,text,LM Studio更新支持本地运行Claude Code,2026-02-01,LM Studio更新支持本地运行Claude Code,LM Studio 新版本支持 Anthropic 兼容 API，可连接 Claude Code。,https://lmstudio.ai/blog/claudecode,primary,candidate,2026-02-12,LM Studio 新版本支持 Anthropic 兼容 API，可连接 Claude Code。,data/raw/wechat/2026-02-01.md,2,from_ai_daily_primary_link
C00003,cmp_openai,OpenAI,daily_report_fact,text,Nvidia据称搁置OpenAI千亿协议,2026-02-01,Nvidia据称搁置OpenAI千亿协议,Nvidia 与 OpenAI 相关合作进展报道。,https://www.wsj.com/tech/ai/the-100-billion-megadeal-between-openai-and-nvidia-is-on-ice-aa3025e3,primary,candidate,2026-02-12,Nvidia 与 OpenAI 相关合作进展报道。,data/raw/wechat/2026-02-01.md,4,from_ai_daily_primary_link
C00004,cmp_meta,Meta,daily_report_fact,text,苹果AI核心团队动荡，多人转投Meta谷歌,2026-02-01,苹果AI核心团队动荡，多人转投Meta谷歌,苹果 AI 团队人员流动相关报道。,https://www.bloomberg.com/news/articles/2026-01-30/apple-loses-more-ai-researchers-and-a-siri-executive-in-latest-departures,primary,candidate,2026-02-12,苹果 AI 团队人员流动相关报道。,data/raw/wechat/2026-02-01.md,5,from_ai_daily_primary_link
C00005,cmp_openai,OpenAI,daily_report_fact,text,OpenAI 发布 Codex App,2026-02-03,OpenAI 发布 Codex App,OpenAI 发布 Codex App 桌面应用，支持多 Agent 并行协作、代码对比、终端视图与自动化任务。付费用户已开放，免费与 Go 用户限时开放。,https://openai.com/index/introducing-the-codex-app/,primary,candidate,2026-02-12,OpenAI 发布 Codex App 桌面应用，支持多 Agent 并行协作、代码对比、终端视图与自动化任务。付费用户已开放，免费与 Go 用户限时开放。,data/raw/wechat/2026-02-03.md,1,from_ai_daily_primary_link
C00006,cmp_xai,xAI,daily_report_fact,text,SpaceX正式收购xAI,2026-02-03,SpaceX正式收购xAI,SpaceX 与 xAI 合并相关消息发布，涉及交易规模与算力基础设施计划。,https://www.spacex.com/updates#xai-joins-spacex,primary,candidate,2026-02-12,SpaceX 与 xAI 合并相关消息发布，涉及交易规模与算力基础设施计划。,data/raw/wechat/2026-02-03.md,3,from_ai_daily_primary_link
C00007,cmp_xai,xAI,daily_report_fact,text,xAI正式发布Grok Imagine 1.0视频模型,2026-02-03,xAI正式发布Grok Imagine 1.0视频模型,xAI 发布 Grok Imagine 1.0，支持生成 10 秒 720p 视频。,http://grok.com/imagine,primary,candidate,2026-02-12,xAI 发布 Grok Imagine 1.0，支持生成 10 秒 720p 视频。,data/raw/wechat/2026-02-03.md,6,from_ai_daily_primary_link
C00008,cmp_openai,OpenAI,daily_report_fact,text,Snowflake与OpenAI达成2亿美元模型集成合作,2026-02-03,Snowflake与OpenAI达成2亿美元模型集成合作,Snowflake 与 OpenAI 宣布多年合作，将模型接入企业 AI 平台。,https://openai.com/index/snowflake-partnership/,primary,candidate,2026-02-12,Snowflake 与 OpenAI 宣布多年合作，将模型接入企业 AI 平台。,data/raw/wechat/2026-02-03.md,9,from_ai_daily_primary_link
C00009,cmp_google,Google,daily_report_fact,text,谷歌 Game Arena 新增狼人杀和扑克基准测试,2026-02-03,谷歌 Game Arena 新增狼人杀和扑克基准测试,Google DeepMind 与 Kaggle 扩展 Game Arena 基准。,https://blog.google/innovation-and-ai/models-and-research/google-deepmind/kaggle-game-arena-updates/,primary,candidate,2026-02-12,Google DeepMind 与 Kaggle 扩展 Game Arena 基准。,data/raw/wechat/2026-02-03.md,10,from_ai_daily_primary_link
C00010,cmp_google,Google,daily_report_fact,text,Google Gemini研究揭示数学猜想新解法,2026-02-03,Google Gemini研究揭示数学猜想新解法,Google 发布数学发现研究，涵盖开放问题评估与解法发现。,https://arxiv.org/abs/2601.22401,primary,candidate,2026-02-12,Google 发布数学发现研究，涵盖开放问题评估与解法发现。,data/raw/wechat/2026-02-03.md,11,from_ai_daily_primary_link
C00011,cmp_openbmb,OpenBMB,daily_report_fact,text,OpenBMB发布多模态模型MiniCPM-o 4.5,2026-02-04,OpenBMB发布多模态模型MiniCPM-o 4.5,OpenBMB 发布 MiniCPM-o 4.5，多模态实时交互能力增强。,https://github.com/OpenBMB/MiniCPM-o,primary,candidate,2026-02-12,OpenBMB 发布 MiniCPM-o 4.5，多模态实时交互能力增强。,data/raw/wechat/2026-02-04.md,3,from_ai_daily_primary_link
C00012,cmp_openrouter,OpenRouter,daily_report_fact,text,OpenRouter推出免费模型路由,2026-02-04,OpenRouter推出免费模型路由,OpenRouter 推出按能力自动筛选的免费模型路由。,https://openrouter.ai/openrouter/free,primary,candidate,2026-02-12,OpenRouter 推出按能力自动筛选的免费模型路由。,data/raw/wechat/2026-02-04.md,7,from_ai_daily_primary_link
C00013,cmp_anthropic,Anthropic,daily_report_fact,text,Anthropic研究：AI错误随难度增加而不连贯,2026-02-04,Anthropic研究：AI错误随难度增加而不连贯,Anthropic 发布相关对齐与行为研究。,https://arxiv.org/abs/2601.23045,primary,candidate,2026-02-12,Anthropic 发布相关对齐与行为研究。,data/raw/wechat/2026-02-04.md,20,from_ai_daily_primary_link
C00014,cmp_anthropic,Anthropic,daily_report_fact,text,Anthropic被曝开发图像生成模型,2026-02-04,Anthropic被曝开发图像生成模型,社区观察到相关线索，尚无官方确认。,https://arena.ai/zh/c/new,primary,candidate,2026-02-12,社区观察到相关线索，尚无官方确认。,data/raw/wechat/2026-02-04.md,24,from_ai_daily_primary_link
C00015,cmp_hugging-face,Hugging Face,daily_report_fact,text,上海AI实验室推出万亿参数多模态科学推理模型Intern-S1-Pro,2026-02-05,上海AI实验室推出万亿参数多模态科学推理模型Intern-S1-Pro,上海AI实验室发布并开源 Intern-S1-Pro，面向 AI4Science，兼容 OpenAI API，可通过 Hugging Face 获取。,https://huggingface.co/internlm/Intern-S1-Pro,primary,candidate,2026-02-12,上海AI实验室发布并开源 Intern-S1-Pro，面向 AI4Science，兼容 OpenAI API，可通过 Hugging Face 获取。,data/raw/wechat/2026-02-05.md,1,from_ai_daily_primary_link
C00016,cmp_openai,OpenAI,daily_report_fact,text,上海AI实验室推出万亿参数多模态科学推理模型Intern-S1-Pro,2026-02-05,上海AI实验室推出万亿参数多模态科学推理模型Intern-S1-Pro,上海AI实验室发布并开源 Intern-S1-Pro，面向 AI4Science，兼容 OpenAI API，可通过 Hugging Face 获取。,https://huggingface.co/internlm/Intern-S1-Pro,primary,candidate,2026-02-12,上海AI实验室发布并开源 Intern-S1-Pro，面向 AI4Science，兼容 OpenAI API，可通过 Hugging Face 获取。,data/raw/wechat/2026-02-05.md,1,from_ai_daily_primary_link
C00017,cmp_mistral-ai,Mistral AI,daily_report_fact,text,Mistral AI开源40亿参数实时语音模型Voxtral Mini 4B Realtime 2602,2026-02-05,Mistral AI开源40亿参数实时语音模型Voxtral Mini 4B Realtime 2602,Mistral AI 发布开源多语言实时语音转录模型，支持设备端部署。,https://huggingface.co/mistralai/Voxtral-Mini-4B-Realtime-2602,primary,candidate,2026-02-12,Mistral AI 发布开源多语言实时语音转录模型，支持设备端部署。,data/raw/wechat/2026-02-05.md,2,from_ai_daily_primary_link
C00018,cmp_google,Google,daily_report_fact,text,Google财报披露AI业务推动营收创新高,2026-02-05,Google财报披露AI业务推动营收创新高,,https://blog.google/company-news/inside-google/message-ceo/alphabet-earnings-q4-2025/#full-stack-approach-ai,primary,candidate,2026-02-12,,data/raw/wechat/2026-02-05.md,18,from_ai_daily_primary_link
C00019,cmp_anthropic,Anthropic,daily_report_fact,text,Anthropic宣布Claude保持无广告,2026-02-05,Anthropic宣布Claude保持无广告,,https://www.anthropic.com/news/claude-is-a-space-to-think,primary,candidate,2026-02-12,,data/raw/wechat/2026-02-05.md,19,from_ai_daily_primary_link
C00020,cmp_meta,Meta,daily_report_fact,text,Meta AI发布EB-JEPA开源库,2026-02-05,Meta AI发布EB-JEPA开源库,,https://github.com/facebookresearch/eb_jepa,primary,candidate,2026-02-12,,data/raw/wechat/2026-02-05.md,24,from_ai_daily_primary_link
C00021,cmp_openai,OpenAI,daily_report_fact,text,传英伟达准备投资OpenAI 200亿美元,2026-02-05,传英伟达准备投资OpenAI 200亿美元,---,https://www.bloomberg.com/news/articles/2026-02-03/nvidia-nears-deal-to-invest-20-billion-in-openai-round,primary,candidate,2026-02-12,---,data/raw/wechat/2026-02-05.md,29,from_ai_daily_primary_link
C00022,cmp_anthropic,Anthropic,daily_report_fact,text,Anthropic发布Claude Opus 4.6,2026-02-06,Anthropic发布Claude Opus 4.6,Anthropic 发布 Claude Opus 4.6，定位为最强 Agent 与编程模型。支持 1M token 上下文，最大输出达 128K。引入自适应思考模式与 Effort 参数，优化长对话处理。已在 claude.ai、API、云平台及第三方编程工具上线。,https://www.anthropic.com/news/claude-opus-4-6,primary,candidate,2026-02-12,Anthropic 发布 Claude Opus 4.6，定位为最强 Agent 与编程模型。支持 1M token 上下文，最大输出达 128K。引入自适应思考模式与 Effort 参数，优化长对话处理。已在 claude.ai、API、云平台及第三方编程工具上线。,data/raw/wechat/2026-02-06.md,1,from_ai_daily_primary_link
C00023,cpt_claude-opus-4-6,Claude Opus 4.6,daily_report_fact,text,Anthropic发布Claude Opus 4.6,2026-02-06,Anthropic发布Claude Opus 4.6,Anthropic 发布 Claude Opus 4.6，定位为最强 Agent 与编程模型。支持 1M token 上下文，最大输出达 128K。引入自适应思考模式与 Effort 参数，优化长对话处理。已在 claude.ai、API、云平台及第三方编程工具上线。,https://www.anthropic.com/news/claude-opus-4-6,primary,candidate,2026-02-12,Anthropic 发布 Claude Opus 4.6，定位为最强 Agent 与编程模型。支持 1M token 上下文，最大输出达 128K。引入自适应思考模式与 Effort 参数，优化长对话处理。已在 claude.ai、API、云平台及第三方编程工具上线。,data/raw/wechat/2026-02-06.md,1,from_ai_daily_primary_link
C00024,cpt_gpt-5-3-codex,GPT-5.3-Codex,daily_report_fact,text,OpenAI发布GPT-5.3-Codex,2026-02-06,OpenAI发布GPT-5.3-Codex,OpenAI 发布 GPT-5.3-Codex，整合模型编码与推理能力，速度提升 25%，支持实时交互与中途引导。模型已在 Codex 上线，API 将陆续开放。,https://openai.com/index/introducing-gpt-5-3-codex/,primary,candidate,2026-02-12,OpenAI 发布 GPT-5.3-Codex，整合模型编码与推理能力，速度提升 25%，支持实时交互与中途引导。模型已在 Codex 上线，API 将陆续开放。,data/raw/wechat/2026-02-06.md,2,from_ai_daily_primary_link
C00025,cmp_openai,OpenAI,daily_report_fact,text,OpenAI发布GPT-5.3-Codex,2026-02-06,OpenAI发布GPT-5.3-Codex,OpenAI 发布 GPT-5.3-Codex，整合模型编码与推理能力，速度提升 25%，支持实时交互与中途引导。模型已在 Codex 上线，API 将陆续开放。,https://openai.com/index/introducing-gpt-5-3-codex/,primary,candidate,2026-02-12,OpenAI 发布 GPT-5.3-Codex，整合模型编码与推理能力，速度提升 25%，支持实时交互与中途引导。模型已在 Codex 上线，API 将陆续开放。,data/raw/wechat/2026-02-06.md,2,from_ai_daily_primary_link
C00026,cmp_openai,OpenAI,daily_report_fact,text,OpenAI 推出企业 AI Agent平台 Frontier,2026-02-06,OpenAI 推出企业 AI Agent平台 Frontier,OpenAI 推出企业级平台 Frontier，支持企业构建、部署及管理 AI Agent。平台提供共享业务上下文、权限治理与持续学习机制，已向部分客户开放。,https://openai.com/index/introducing-openai-frontier/,primary,candidate,2026-02-12,OpenAI 推出企业级平台 Frontier，支持企业构建、部署及管理 AI Agent。平台提供共享业务上下文、权限治理与持续学习机制，已向部分客户开放。,data/raw/wechat/2026-02-06.md,4,from_ai_daily_primary_link
C00027,cpt_gpt-5-3-codex,GPT-5.3-Codex,daily_report_fact,text,OpenAI 推出 Trusted Access for Cyber 试点项目,2026-02-06,OpenAI 推出 Trusted Access for Cyber 试点项目,OpenAI 推出 Trusted Access for Cyber 试点项目，向防御方提供其最强推理模型 GPT-5.3-Codex，并配套 1000 万美元 API 积分支持网络安全工作。,https://openai.com/index/trusted-access-for-cyber/,primary,candidate,2026-02-12,OpenAI 推出 Trusted Access for Cyber 试点项目，向防御方提供其最强推理模型 GPT-5.3-Codex，并配套 1000 万美元 API 积分支持网络安全工作。,data/raw/wechat/2026-02-06.md,5,from_ai_daily_primary_link
C00028,cmp_openai,OpenAI,daily_report_fact,text,OpenAI 推出 Trusted Access for Cyber 试点项目,2026-02-06,OpenAI 推出 Trusted Access for Cyber 试点项目,OpenAI 推出 Trusted Access for Cyber 试点项目，向防御方提供其最强推理模型 GPT-5.3-Codex，并配套 1000 万美元 API 积分支持网络安全工作。,https://openai.com/index/trusted-access-for-cyber/,primary,candidate,2026-02-12,OpenAI 推出 Trusted Access for Cyber 试点项目，向防御方提供其最强推理模型 GPT-5.3-Codex，并配套 1000 万美元 API 积分支持网络安全工作。,data/raw/wechat/2026-02-06.md,5,from_ai_daily_primary_link
C00029,cmp_jetbrains,JetBrains,daily_report_fact,text,Kiro CLI 引入 Agent Client Protocol 支持,2026-02-06,Kiro CLI 引入 Agent Client Protocol 支持,Kiro CLI 已支持 Agent Client Protocol（ACP），使其 AI 功能可在 Eclipse、Emacs、JetBrains 等多款编程工具中运行。,https://kiro.dev/blog/kiro-adopts-acp/,primary,candidate,2026-02-12,Kiro CLI 已支持 Agent Client Protocol（ACP），使其 AI 功能可在 Eclipse、Emacs、JetBrains 等多款编程工具中运行。,data/raw/wechat/2026-02-06.md,7,from_ai_daily_primary_link
C00030,cmp_google,Google,daily_report_fact,text,Google推出原生自适应无障碍框架,2026-02-06,Google推出原生自适应无障碍框架,Google 推出 NAI 框架，旨在将无障碍功能从设计之初就融入产品，通过 AI 重构界面提供个性化体验。,https://blog.google/company-news/outreach-and-initiatives/accessibility/natively-adaptive-interfaces-ai-accessibility/,primary,candidate,2026-02-12,Google 推出 NAI 框架，旨在将无障碍功能从设计之初就融入产品，通过 AI 重构界面提供个性化体验。,data/raw/wechat/2026-02-06.md,9,from_ai_daily_primary_link
C00031,cmp_openai,OpenAI,daily_report_fact,text,OpenAI揭晓Codex核心架构,2026-02-06,OpenAI揭晓Codex核心架构,OpenAI 介绍 Codex 核心架构，核心是双向 JSON-RPC API “Codex App Server”，统一支持网页版、CLI、IDE 扩展等。,https://github.com/openai/codex/discussions/9956,primary,candidate,2026-02-12,OpenAI 介绍 Codex 核心架构，核心是双向 JSON-RPC API “Codex App Server”，统一支持网页版、CLI、IDE 扩展等。,data/raw/wechat/2026-02-06.md,15,from_ai_daily_primary_link
C00032,cmp_cursor,Cursor,daily_report_fact,text,Cursor发布多智能体编程研究框架,2026-02-06,Cursor发布多智能体编程研究框架,Cursor 推出多智能体编程研究框架预览版，支持大量编程 agent 并行运行。,https://cursor.com/cn/blog/self-driving-codebases,primary,candidate,2026-02-12,Cursor 推出多智能体编程研究框架预览版，支持大量编程 agent 并行运行。,data/raw/wechat/2026-02-06.md,16,from_ai_daily_primary_link
C00033,cmp_anthropic,Anthropic,daily_report_fact,text,Anthropic揭示基础设施配置影响 Agent 评估,2026-02-06,Anthropic揭示基础设施配置影响 Agent 评估,Anthropic 发布研究指出，基础设施配置（如内存配额、容器策略）会显著影响 Agent 编码评估结果。,https://www.anthropic.com/engineering/infrastructure-noise,primary,candidate,2026-02-12,Anthropic 发布研究指出，基础设施配置（如内存配额、容器策略）会显著影响 Agent 编码评估结果。,data/raw/wechat/2026-02-06.md,17,from_ai_daily_primary_link
C00034,cmp_openai,OpenAI,daily_report_fact,text,OpenAI与Ginkgo合作推出AI实验室降低合成成本40%,2026-02-06,OpenAI与Ginkgo合作推出AI实验室降低合成成本40%,OpenAI 与 Ginkgo Bioworks 合作，结合 GPT-5 与云实验室平台，将无细胞蛋白质合成成本降低约 40%。,https://openai.com/index/gpt-5-lowers-protein-synthesis-cost/,primary,candidate,2026-02-12,OpenAI 与 Ginkgo Bioworks 合作，结合 GPT-5 与云实验室平台，将无细胞蛋白质合成成本降低约 40%。,data/raw/wechat/2026-02-06.md,19,from_ai_daily_primary_link
C00035,cpt_longcat,LongCat,daily_report_fact,text,美团推出LongCat-Flash-Lite模型,2026-02-07,美团推出LongCat-Flash-Lite模型,美团龙猫团队发布并开源 LongCat-Flash-Lite（68.5B MoE），强调高吞吐与 Agent/代码场景。,https://huggingface.co/meituan-longcat/LongCat-Flash-Lite,primary,candidate,2026-02-12,美团龙猫团队发布并开源 LongCat-Flash-Lite（68.5B MoE），强调高吞吐与 Agent/代码场景。,data/raw/wechat/2026-02-07.md,1,from_ai_daily_primary_link
C00036,cpt_longcat-flash-lite,LongCat-Flash-Lite,daily_report_fact,text,美团推出LongCat-Flash-Lite模型,2026-02-07,美团推出LongCat-Flash-Lite模型,美团龙猫团队发布并开源 LongCat-Flash-Lite（68.5B MoE），强调高吞吐与 Agent/代码场景。,https://huggingface.co/meituan-longcat/LongCat-Flash-Lite,primary,candidate,2026-02-12,美团龙猫团队发布并开源 LongCat-Flash-Lite（68.5B MoE），强调高吞吐与 Agent/代码场景。,data/raw/wechat/2026-02-07.md,1,from_ai_daily_primary_link
C00037,cpt_seedance-2-0,Seedance 2.0,daily_report_fact,text,字节跳动发布视频生成模型 Seedance 2.0,2026-02-07,字节跳动发布视频生成模型 Seedance 2.0,字节跳动发布 Seedance 2.0，支持图像/视频/音频/文本四模态输入生成 4-15 秒视频。,https://bytedance.larkoffice.com/wiki/A5RHwWhoBiOnjukIIw6cu5ybnXQ,primary,candidate,2026-02-12,字节跳动发布 Seedance 2.0，支持图像/视频/音频/文本四模态输入生成 4-15 秒视频。,data/raw/wechat/2026-02-07.md,2,from_ai_daily_primary_link
C00038,cmp_kilo-code,Kilo Code,daily_report_fact,text,OpenRouter与Kilo Code上线 Pony Alpha 模型,2026-02-07,OpenRouter与Kilo Code上线 Pony Alpha 模型,OpenRouter 与 Kilo Code 上线 stealth 模型 Pony Alpha，强调 coding、reasoning 与 agentic workflows。,https://openrouter.ai/openrouter/pony-alpha,primary,candidate,2026-02-12,OpenRouter 与 Kilo Code 上线 stealth 模型 Pony Alpha，强调 coding、reasoning 与 agentic workflows。,data/raw/wechat/2026-02-07.md,3,from_ai_daily_primary_link
C00039,cmp_openrouter,OpenRouter,daily_report_fact,text,OpenRouter与Kilo Code上线 Pony Alpha 模型,2026-02-07,OpenRouter与Kilo Code上线 Pony Alpha 模型,OpenRouter 与 Kilo Code 上线 stealth 模型 Pony Alpha，强调 coding、reasoning 与 agentic workflows。,https://openrouter.ai/openrouter/pony-alpha,primary,candidate,2026-02-12,OpenRouter 与 Kilo Code 上线 stealth 模型 Pony Alpha，强调 coding、reasoning 与 agentic workflows。,data/raw/wechat/2026-02-07.md,3,from_ai_daily_primary_link
C00040,cpt_pony-alpha,Pony Alpha,daily_report_fact,text,OpenRouter与Kilo Code上线 Pony Alpha 模型,2026-02-07,OpenRouter与Kilo Code上线 Pony Alpha 模型,OpenRouter 与 Kilo Code 上线 stealth 模型 Pony Alpha，强调 coding、reasoning 与 agentic workflows。,https://openrouter.ai/openrouter/pony-alpha,primary,candidate,2026-02-12,OpenRouter 与 Kilo Code 上线 stealth 模型 Pony Alpha，强调 coding、reasoning 与 agentic workflows。,data/raw/wechat/2026-02-07.md,3,from_ai_daily_primary_link
C00041,cmp_waymo,Waymo,daily_report_fact,text,Waymo推出Waymo World Model,2026-02-07,Waymo推出Waymo World Model,Waymo 推出基于 Genie 3 的 Waymo World Model，用于自动驾驶仿真训练。,https://waymo.com/blog/2026/02/the-waymo-world-model-a-new-frontier-for-autonomous-driving-simulation,primary,candidate,2026-02-12,Waymo 推出基于 Genie 3 的 Waymo World Model，用于自动驾驶仿真训练。,data/raw/wechat/2026-02-07.md,4,from_ai_daily_primary_link
C00042,cpt_waymo-world-model,Waymo World Model,daily_report_fact,text,Waymo推出Waymo World Model,2026-02-07,Waymo推出Waymo World Model,Waymo 推出基于 Genie 3 的 Waymo World Model，用于自动驾驶仿真训练。,https://waymo.com/blog/2026/02/the-waymo-world-model-a-new-frontier-for-autonomous-driving-simulation,primary,candidate,2026-02-12,Waymo 推出基于 Genie 3 的 Waymo World Model，用于自动驾驶仿真训练。,data/raw/wechat/2026-02-07.md,4,from_ai_daily_primary_link
C00043,cmp_openai,OpenAI,daily_report_fact,text,OpenAI开放Sora真人角色视频生成功能,2026-02-07,OpenAI开放Sora真人角色视频生成功能,OpenAI 更新 Sora，支持真人角色图像生成视频与个性化角色创建。,https://help.openai.com/en/articles/12593142-sora-release-notes#image-2-video-with-people,primary,candidate,2026-02-12,OpenAI 更新 Sora，支持真人角色图像生成视频与个性化角色创建。,data/raw/wechat/2026-02-07.md,6,from_ai_daily_primary_link
C00044,cpt_sora,Sora,daily_report_fact,text,OpenAI开放Sora真人角色视频生成功能,2026-02-07,OpenAI开放Sora真人角色视频生成功能,OpenAI 更新 Sora，支持真人角色图像生成视频与个性化角色创建。,https://help.openai.com/en/articles/12593142-sora-release-notes#image-2-video-with-people,primary,candidate,2026-02-12,OpenAI 更新 Sora，支持真人角色图像生成视频与个性化角色创建。,data/raw/wechat/2026-02-07.md,6,from_ai_daily_primary_link
C00045,cpt_model-council,Model Council,daily_report_fact,text,Perplexity推出多模型聚合问答功能,2026-02-07,Perplexity推出多模型聚合问答功能,Perplexity 推出 Model Council，单次查询并行调用多模型并输出综合答案。,https://www.perplexity.ai/hub/blog/introducing-model-council,primary,candidate,2026-02-12,Perplexity 推出 Model Council，单次查询并行调用多模型并输出综合答案。,data/raw/wechat/2026-02-07.md,7,from_ai_daily_primary_link
C00046,cmp_perplexity,Perplexity,daily_report_fact,text,Perplexity推出多模型聚合问答功能,2026-02-07,Perplexity推出多模型聚合问答功能,Perplexity 推出 Model Council，单次查询并行调用多模型并输出综合答案。,https://www.perplexity.ai/hub/blog/introducing-model-council,primary,candidate,2026-02-12,Perplexity 推出 Model Council，单次查询并行调用多模型并输出综合答案。,data/raw/wechat/2026-02-07.md,7,from_ai_daily_primary_link
C00047,cmp_anthropic,Anthropic,daily_report_fact,text,Anthropic推出Claude Opus 4.6快速模式,2026-02-08,Anthropic推出Claude Opus 4.6快速模式,Anthropic 为 Claude Opus 4.6 推出 fast mode，称速度约提升 2.5 倍，采用分档 token 定价并提供限时折扣。,https://code.claude.com/docs/en/fast-mode,primary,candidate,2026-02-12,Anthropic 为 Claude Opus 4.6 推出 fast mode，称速度约提升 2.5 倍，采用分档 token 定价并提供限时折扣。,data/raw/wechat/2026-02-08.md,1,from_ai_daily_primary_link
C00048,cpt_claude-opus-4-6,Claude Opus 4.6,daily_report_fact,text,Anthropic推出Claude Opus 4.6快速模式,2026-02-08,Anthropic推出Claude Opus 4.6快速模式,Anthropic 为 Claude Opus 4.6 推出 fast mode，称速度约提升 2.5 倍，采用分档 token 定价并提供限时折扣。,https://code.claude.com/docs/en/fast-mode,primary,candidate,2026-02-12,Anthropic 为 Claude Opus 4.6 推出 fast mode，称速度约提升 2.5 倍，采用分档 token 定价并提供限时折扣。,data/raw/wechat/2026-02-08.md,1,from_ai_daily_primary_link
C00049,cmp_augment-code,Augment Code,daily_report_fact,text,Augment Code正式上线Context Engine MCP,2026-02-08,Augment Code正式上线Context Engine MCP,Augment Code 宣布 Context Engine MCP 结束测试并正式上线，面向 MCP 兼容 AI 编码工具。,https://www.augmentcode.com/blog/context-engine-mcp-now-live,primary,candidate,2026-02-12,Augment Code 宣布 Context Engine MCP 结束测试并正式上线，面向 MCP 兼容 AI 编码工具。,data/raw/wechat/2026-02-08.md,2,from_ai_daily_primary_link
C00050,cpt_context-engine-mcp,Context Engine MCP,daily_report_fact,text,Augment Code正式上线Context Engine MCP,2026-02-08,Augment Code正式上线Context Engine MCP,Augment Code 宣布 Context Engine MCP 结束测试并正式上线，面向 MCP 兼容 AI 编码工具。,https://www.augmentcode.com/blog/context-engine-mcp-now-live,primary,candidate,2026-02-12,Augment Code 宣布 Context Engine MCP 结束测试并正式上线，面向 MCP 兼容 AI 编码工具。,data/raw/wechat/2026-02-08.md,2,from_ai_daily_primary_link
C00051,prs_brendan-gregg,Brendan Gregg,daily_report_fact,text,OpenAI引入性能专家优化数据中心成本,2026-02-08,OpenAI引入性能专家优化数据中心成本,性能专家 Brendan Gregg 加入 OpenAI ChatGPT 性能工程团队，聚焦数据中心效率与成本优化。,https://www.brendangregg.com/blog/2026-02-07/why-i-joined-openai.html,primary,candidate,2026-02-12,性能专家 Brendan Gregg 加入 OpenAI ChatGPT 性能工程团队，聚焦数据中心效率与成本优化。,data/raw/wechat/2026-02-08.md,3,from_ai_daily_primary_link
C00052,cmp_openai,OpenAI,daily_report_fact,text,OpenAI引入性能专家优化数据中心成本,2026-02-08,OpenAI引入性能专家优化数据中心成本,性能专家 Brendan Gregg 加入 OpenAI ChatGPT 性能工程团队，聚焦数据中心效率与成本优化。,https://www.brendangregg.com/blog/2026-02-07/why-i-joined-openai.html,primary,candidate,2026-02-12,性能专家 Brendan Gregg 加入 OpenAI ChatGPT 性能工程团队，聚焦数据中心效率与成本优化。,data/raw/wechat/2026-02-08.md,3,from_ai_daily_primary_link
C00053,cmp_openai,OpenAI,daily_report_fact,text,OpenAI 推进AI模型本土化策略,2026-02-08,OpenAI 推进AI模型本土化策略,OpenAI 推进本地化方案（OpenAI for Countries），包含爱沙尼亚与阿联酋相关项目。,https://openai.com/index/our-approach-to-localization/,primary,candidate,2026-02-12,OpenAI 推进本地化方案（OpenAI for Countries），包含爱沙尼亚与阿联酋相关项目。,data/raw/wechat/2026-02-08.md,4,from_ai_daily_primary_link
C00054,cpt_openai-for-countries,OpenAI for Countries,daily_report_fact,text,OpenAI 推进AI模型本土化策略,2026-02-08,OpenAI 推进AI模型本土化策略,OpenAI 推进本地化方案（OpenAI for Countries），包含爱沙尼亚与阿联酋相关项目。,https://openai.com/index/our-approach-to-localization/,primary,candidate,2026-02-12,OpenAI 推进本地化方案（OpenAI for Countries），包含爱沙尼亚与阿联酋相关项目。,data/raw/wechat/2026-02-08.md,4,from_ai_daily_primary_link
C00055,cpt_plawbench,PLawBench,daily_report_fact,text,千问Qwen等联合推出法律评测基准PLawBench,2026-02-08,千问Qwen等联合推出法律评测基准PLawBench,Qwen 团队联合发布法律评测基准 PLawBench，覆盖法律咨询、案例分析与文书生成。,https://arxiv.org/abs/2601.16669,primary,candidate,2026-02-12,Qwen 团队联合发布法律评测基准 PLawBench，覆盖法律咨询、案例分析与文书生成。,data/raw/wechat/2026-02-08.md,5,from_ai_daily_primary_link
C00056,cpt_carplay,CarPlay,daily_report_fact,text,苹果计划为CarPlay引入第三方AI语音,2026-02-08,苹果计划为CarPlay引入第三方AI语音,外媒报道苹果计划为 CarPlay 引入第三方 AI 语音助手支持。,https://www.bloomberg.com/news/articles/2026-02-06/apple-plans-to-allow-outside-voice-controlled-ai-chatbots-in-carplay,primary,candidate,2026-02-12,外媒报道苹果计划为 CarPlay 引入第三方 AI 语音助手支持。,data/raw/wechat/2026-02-08.md,6,from_ai_daily_primary_link
C00057,cpt_gated-deltanet,Gated DeltaNet,daily_report_fact,text,Qwen 3.5系列模型即将发布（原文）,2026-02-09,Qwen 3.5系列模型即将发布（原文）,千问团队正在推进 Qwen 3.5 系列模型的发布，其已向 Transformers 代码库提交相关支持 PR。该系列模型采用混合架构，结合 Gated DeltaNet 与混合注意力机制，原生支持多模态输入。,https://github.com/huggingface/transformers/pull/43830/,primary,candidate,2026-02-12,千问团队正在推进 Qwen 3.5 系列模型的发布，其已向 Transformers 代码库提交相关支持 PR。该系列模型采用混合架构，结合 Gated DeltaNet 与混合注意力机制，原生支持多模态输入。,data/raw/wechat/2026-02-09.md,1,from_ai_daily_primary_link
C00058,cmp_hugging-face,Hugging Face,daily_report_fact,text,Qwen 3.5系列模型即将发布（原文）,2026-02-09,Qwen 3.5系列模型即将发布（原文）,千问团队正在推进 Qwen 3.5 系列模型的发布，其已向 Transformers 代码库提交相关支持 PR。该系列模型采用混合架构，结合 Gated DeltaNet 与混合注意力机制，原生支持多模态输入。,https://github.com/huggingface/transformers/pull/43830/,primary,candidate,2026-02-12,千问团队正在推进 Qwen 3.5 系列模型的发布，其已向 Transformers 代码库提交相关支持 PR。该系列模型采用混合架构，结合 Gated DeltaNet 与混合注意力机制，原生支持多模态输入。,data/raw/wechat/2026-02-09.md,1,from_ai_daily_primary_link
C00059,cpt_qwen-3-5,Qwen 3.5,daily_report_fact,text,Qwen 3.5系列模型即将发布（原文）,2026-02-09,Qwen 3.5系列模型即将发布（原文）,千问团队正在推进 Qwen 3.5 系列模型的发布，其已向 Transformers 代码库提交相关支持 PR。该系列模型采用混合架构，结合 Gated DeltaNet 与混合注意力机制，原生支持多模态输入。,https://github.com/huggingface/transformers/pull/43830/,primary,candidate,2026-02-12,千问团队正在推进 Qwen 3.5 系列模型的发布，其已向 Transformers 代码库提交相关支持 PR。该系列模型采用混合架构，结合 Gated DeltaNet 与混合注意力机制，原生支持多模态输入。,data/raw/wechat/2026-02-09.md,1,from_ai_daily_primary_link
C00060,cpt_qwen3-5-35b-a3b-instruct,Qwen3.5-35B-A3B-Instruct,daily_report_fact,text,Qwen 3.5系列模型即将发布（原文）,2026-02-09,Qwen 3.5系列模型即将发布（原文）,千问团队正在推进 Qwen 3.5 系列模型的发布，其已向 Transformers 代码库提交相关支持 PR。该系列模型采用混合架构，结合 Gated DeltaNet 与混合注意力机制，原生支持多模态输入。,https://github.com/huggingface/transformers/pull/43830/,primary,candidate,2026-02-12,千问团队正在推进 Qwen 3.5 系列模型的发布，其已向 Transformers 代码库提交相关支持 PR。该系列模型采用混合架构，结合 Gated DeltaNet 与混合注意力机制，原生支持多模态输入。,data/raw/wechat/2026-02-09.md,1,from_ai_daily_primary_link
C00061,cpt_qwen3-5-9b-instruct,Qwen3.5-9B-Instruct,daily_report_fact,text,Qwen 3.5系列模型即将发布（原文）,2026-02-09,Qwen 3.5系列模型即将发布（原文）,千问团队正在推进 Qwen 3.5 系列模型的发布，其已向 Transformers 代码库提交相关支持 PR。该系列模型采用混合架构，结合 Gated DeltaNet 与混合注意力机制，原生支持多模态输入。,https://github.com/huggingface/transformers/pull/43830/,primary,candidate,2026-02-12,千问团队正在推进 Qwen 3.5 系列模型的发布，其已向 Transformers 代码库提交相关支持 PR。该系列模型采用混合架构，结合 Gated DeltaNet 与混合注意力机制，原生支持多模态输入。,data/raw/wechat/2026-02-09.md,1,from_ai_daily_primary_link
C00062,cpt_grok-imagine-image,Grok Imagine Image,daily_report_fact,text,xAI上线Grok Imagine Image Pro 模型 API（原文）,2026-02-09,xAI上线Grok Imagine Image Pro 模型 API（原文）,xAI 近日正式宣布推出名为 Grok Imagine Image Pro 与 Grok Imagine 的图像生成模型，支持文本生图、图像编辑、风格迁移及批量生成。用户可通过 API 调用这两款模型。,https://docs.x.ai/developers/model-capabilities/images/generation,primary,candidate,2026-02-12,xAI 近日正式宣布推出名为 Grok Imagine Image Pro 与 Grok Imagine 的图像生成模型，支持文本生图、图像编辑、风格迁移及批量生成。用户可通过 API 调用这两款模型。,data/raw/wechat/2026-02-09.md,2,from_ai_daily_primary_link
C00063,cpt_grok-imagine-image-pro,Grok Imagine Image Pro,daily_report_fact,text,xAI上线Grok Imagine Image Pro 模型 API（原文）,2026-02-09,xAI上线Grok Imagine Image Pro 模型 API（原文）,xAI 近日正式宣布推出名为 Grok Imagine Image Pro 与 Grok Imagine 的图像生成模型，支持文本生图、图像编辑、风格迁移及批量生成。用户可通过 API 调用这两款模型。,https://docs.x.ai/developers/model-capabilities/images/generation,primary,candidate,2026-02-12,xAI 近日正式宣布推出名为 Grok Imagine Image Pro 与 Grok Imagine 的图像生成模型，支持文本生图、图像编辑、风格迁移及批量生成。用户可通过 API 调用这两款模型。,data/raw/wechat/2026-02-09.md,2,from_ai_daily_primary_link
C00064,cmp_xai,xAI,daily_report_fact,text,xAI上线Grok Imagine Image Pro 模型 API（原文）,2026-02-09,xAI上线Grok Imagine Image Pro 模型 API（原文）,xAI 近日正式宣布推出名为 Grok Imagine Image Pro 与 Grok Imagine 的图像生成模型，支持文本生图、图像编辑、风格迁移及批量生成。用户可通过 API 调用这两款模型。,https://docs.x.ai/developers/model-capabilities/images/generation,primary,candidate,2026-02-12,xAI 近日正式宣布推出名为 Grok Imagine Image Pro 与 Grok Imagine 的图像生成模型，支持文本生图、图像编辑、风格迁移及批量生成。用户可通过 API 调用这两款模型。,data/raw/wechat/2026-02-09.md,2,from_ai_daily_primary_link
C00065,cpt_workbuddy,WorkBuddy,daily_report_fact,text,CodeBuddy团队发布AI桌面工作台WorkBuddy（原文）,2026-02-09,CodeBuddy团队发布AI桌面工作台WorkBuddy（原文）,腾讯云CodeBuddy团队发布WorkBuddy，支持自然语言指令执行多模态任务。产品已开放内测，适用于文件处理、PPT生成、海报设计、知识库构建等场景。,https://www.codebuddy.cn/work,primary,candidate,2026-02-12,腾讯云CodeBuddy团队发布WorkBuddy，支持自然语言指令执行多模态任务。产品已开放内测，适用于文件处理、PPT生成、海报设计、知识库构建等场景。,data/raw/wechat/2026-02-09.md,3,from_ai_daily_primary_link
C00066,cpt_avocado,Avocado,daily_report_fact,text,Meta AI 已在官网测试最新模型 Avocado（原文）,2026-02-09,Meta AI 已在官网测试最新模型 Avocado（原文）,有用户发现，Meta AI 更新了其网站与移动应用，正在测试包括新模型 Avocado 在内的多项功能与集成。,https://www.testingcatalog.com/meta-ai-redies-avacado-manus-agent-and-openclaw-integration/,primary,candidate,2026-02-12,有用户发现，Meta AI 更新了其网站与移动应用，正在测试包括新模型 Avocado 在内的多项功能与集成。,data/raw/wechat/2026-02-09.md,5,from_ai_daily_primary_link
C00067,cpt_avocado-thinking,Avocado Thinking,daily_report_fact,text,Meta AI 已在官网测试最新模型 Avocado（原文）,2026-02-09,Meta AI 已在官网测试最新模型 Avocado（原文）,有用户发现，Meta AI 更新了其网站与移动应用，正在测试包括新模型 Avocado 在内的多项功能与集成。,https://www.testingcatalog.com/meta-ai-redies-avacado-manus-agent-and-openclaw-integration/,primary,candidate,2026-02-12,有用户发现，Meta AI 更新了其网站与移动应用，正在测试包括新模型 Avocado 在内的多项功能与集成。,data/raw/wechat/2026-02-09.md,5,from_ai_daily_primary_link
C00068,cpt_big-brain,Big Brain,daily_report_fact,text,Meta AI 已在官网测试最新模型 Avocado（原文）,2026-02-09,Meta AI 已在官网测试最新模型 Avocado（原文）,有用户发现，Meta AI 更新了其网站与移动应用，正在测试包括新模型 Avocado 在内的多项功能与集成。,https://www.testingcatalog.com/meta-ai-redies-avacado-manus-agent-and-openclaw-integration/,primary,candidate,2026-02-12,有用户发现，Meta AI 更新了其网站与移动应用，正在测试包括新模型 Avocado 在内的多项功能与集成。,data/raw/wechat/2026-02-09.md,5,from_ai_daily_primary_link
C00069,cmp_meta,Meta,daily_report_fact,text,Meta AI 已在官网测试最新模型 Avocado（原文）,2026-02-09,Meta AI 已在官网测试最新模型 Avocado（原文）,有用户发现，Meta AI 更新了其网站与移动应用，正在测试包括新模型 Avocado 在内的多项功能与集成。,https://www.testingcatalog.com/meta-ai-redies-avacado-manus-agent-and-openclaw-integration/,primary,candidate,2026-02-12,有用户发现，Meta AI 更新了其网站与移动应用，正在测试包括新模型 Avocado 在内的多项功能与集成。,data/raw/wechat/2026-02-09.md,5,from_ai_daily_primary_link
C00070,cpt_sierra,Sierra,daily_report_fact,text,Meta AI 已在官网测试最新模型 Avocado（原文）,2026-02-09,Meta AI 已在官网测试最新模型 Avocado（原文）,有用户发现，Meta AI 更新了其网站与移动应用，正在测试包括新模型 Avocado 在内的多项功能与集成。,https://www.testingcatalog.com/meta-ai-redies-avacado-manus-agent-and-openclaw-integration/,primary,candidate,2026-02-12,有用户发现，Meta AI 更新了其网站与移动应用，正在测试包括新模型 Avocado 在内的多项功能与集成。,data/raw/wechat/2026-02-09.md,5,from_ai_daily_primary_link
C00071,cmp_openai,OpenAI,daily_report_fact,text,OpenAI正式启动ChatGPT广告测试,2026-02-10,OpenAI正式启动ChatGPT广告测试,OpenAI 在美国面向 Free 与 Go 部分成年用户测试 ChatGPT 广告，强调广告与回答视觉分离、敏感话题不投放、广告商无法获取聊天内容。支持关闭广告但会影响每日免费对话次数。,https://openai.com/index/testing-ads-in-chatgpt/,primary,candidate,2026-02-12,OpenAI 在美国面向 Free 与 Go 部分成年用户测试 ChatGPT 广告，强调广告与回答视觉分离、敏感话题不投放、广告商无法获取聊天内容。支持关闭广告但会影响每日免费对话次数。,data/raw/wechat/2026-02-10.md,1,from_ai_daily_primary_link
C00072,cpt_aurora-alpha,Aurora Alpha,daily_report_fact,text,OpenRouter上线 stealth 模型 Aurora Alpha,2026-02-10,OpenRouter上线 stealth 模型 Aurora Alpha,Aurora Alpha 面向编码助手、实时对话和 agentic workflow，支持 128k 上下文与高输出长度，支持 reasoning 参数。,https://openrouter.ai/openrouter/aurora-alpha,primary,candidate,2026-02-12,Aurora Alpha 面向编码助手、实时对话和 agentic workflow，支持 128k 上下文与高输出长度，支持 reasoning 参数。,data/raw/wechat/2026-02-10.md,3,from_ai_daily_primary_link
C00073,cmp_openrouter,OpenRouter,daily_report_fact,text,OpenRouter上线 stealth 模型 Aurora Alpha,2026-02-10,OpenRouter上线 stealth 模型 Aurora Alpha,Aurora Alpha 面向编码助手、实时对话和 agentic workflow，支持 128k 上下文与高输出长度，支持 reasoning 参数。,https://openrouter.ai/openrouter/aurora-alpha,primary,candidate,2026-02-12,Aurora Alpha 面向编码助手、实时对话和 agentic workflow，支持 128k 上下文与高输出长度，支持 reasoning 参数。,data/raw/wechat/2026-02-10.md,3,from_ai_daily_primary_link
C00074,cpt_composer-1-5,Composer 1.5,daily_report_fact,text,Cursor 上线编程模型 Composer 1.5,2026-02-10,Cursor 上线编程模型 Composer 1.5,Cursor 发布 Composer 1.5，描述为在同基座模型上通过更大规模强化学习得到提升，强调思考 token、自我总结和长任务处理能力。,https://cursor.com/cn/blog/composer-1-5,primary,candidate,2026-02-12,Cursor 发布 Composer 1.5，描述为在同基座模型上通过更大规模强化学习得到提升，强调思考 token、自我总结和长任务处理能力。,data/raw/wechat/2026-02-10.md,4,from_ai_daily_primary_link
C00075,cmp_cursor,Cursor,daily_report_fact,text,Cursor 上线编程模型 Composer 1.5,2026-02-10,Cursor 上线编程模型 Composer 1.5,Cursor 发布 Composer 1.5，描述为在同基座模型上通过更大规模强化学习得到提升，强调思考 token、自我总结和长任务处理能力。,https://cursor.com/cn/blog/composer-1-5,primary,candidate,2026-02-12,Cursor 发布 Composer 1.5，描述为在同基座模型上通过更大规模强化学习得到提升，强调思考 token、自我总结和长任务处理能力。,data/raw/wechat/2026-02-10.md,4,from_ai_daily_primary_link
C00076,cmp_hugging-face,Hugging Face,daily_report_fact,text,Hugging Face发布Transformers.js v4预览版,2026-02-10,Hugging Face发布Transformers.js v4预览版,Transformers.js v4 预览版引入 C++ 重写 WebGPU Runtime，支持更多模型架构与跨环境运行（浏览器/Node/Bun/Deno 等）。,https://huggingface.co/blog/transformersjs-v4,primary,candidate,2026-02-12,Transformers.js v4 预览版引入 C++ 重写 WebGPU Runtime，支持更多模型架构与跨环境运行（浏览器/Node/Bun/Deno 等）。,data/raw/wechat/2026-02-10.md,7,from_ai_daily_primary_link
C00077,cpt_transformers-js-v4,Transformers.js v4,daily_report_fact,text,Hugging Face发布Transformers.js v4预览版,2026-02-10,Hugging Face发布Transformers.js v4预览版,Transformers.js v4 预览版引入 C++ 重写 WebGPU Runtime，支持更多模型架构与跨环境运行（浏览器/Node/Bun/Deno 等）。,https://huggingface.co/blog/transformersjs-v4,primary,candidate,2026-02-12,Transformers.js v4 预览版引入 C++ 重写 WebGPU Runtime，支持更多模型架构与跨环境运行（浏览器/Node/Bun/Deno 等）。,data/raw/wechat/2026-02-10.md,7,from_ai_daily_primary_link
C00078,cpt_dsa,DSA,daily_report_fact,text,智谱GLM-5架构细节曝光总参数或达700B,2026-02-10,智谱GLM-5架构细节曝光总参数或达700B,提到 GLM-5 适配提交、DSA/MTP 技术线索、参数规模推测与上下文长度相关信息，属于前瞻传闻类条目。,https://github.com/huggingface/transformers/pull/43858,primary,candidate,2026-02-12,提到 GLM-5 适配提交、DSA/MTP 技术线索、参数规模推测与上下文长度相关信息，属于前瞻传闻类条目。,data/raw/wechat/2026-02-10.md,10,from_ai_daily_primary_link
C00079,cpt_glm-5,GLM-5,daily_report_fact,text,智谱GLM-5架构细节曝光总参数或达700B,2026-02-10,智谱GLM-5架构细节曝光总参数或达700B,提到 GLM-5 适配提交、DSA/MTP 技术线索、参数规模推测与上下文长度相关信息，属于前瞻传闻类条目。,https://github.com/huggingface/transformers/pull/43858,primary,candidate,2026-02-12,提到 GLM-5 适配提交、DSA/MTP 技术线索、参数规模推测与上下文长度相关信息，属于前瞻传闻类条目。,data/raw/wechat/2026-02-10.md,10,from_ai_daily_primary_link
C00080,cpt_mtp,MTP,daily_report_fact,text,智谱GLM-5架构细节曝光总参数或达700B,2026-02-10,智谱GLM-5架构细节曝光总参数或达700B,提到 GLM-5 适配提交、DSA/MTP 技术线索、参数规模推测与上下文长度相关信息，属于前瞻传闻类条目。,https://github.com/huggingface/transformers/pull/43858,primary,candidate,2026-02-12,提到 GLM-5 适配提交、DSA/MTP 技术线索、参数规模推测与上下文长度相关信息，属于前瞻传闻类条目。,data/raw/wechat/2026-02-10.md,10,from_ai_daily_primary_link
C00081,cpt_qwen-image-2-0,Qwen-Image-2.0,daily_report_fact,text,千问推出Qwen-Image-2.0统一图像模型,2026-02-11,千问推出Qwen-Image-2.0统一图像模型,千问团队发布 Qwen-Image-2.0，统一图像生成与编辑能力，支持 2K 分辨率和长指令，强调专业文字渲染、真实质感、多子图一致性等能力；已在阿里云百炼开放 API，可通过 Qwen Chat 体验，提到后续可能开源传闻。,https://qwen.ai/blog?id=qwen-image-2.0,primary,candidate,2026-02-12,千问团队发布 Qwen-Image-2.0，统一图像生成与编辑能力，支持 2K 分辨率和长指令，强调专业文字渲染、真实质感、多子图一致性等能力；已在阿里云百炼开放 API，可通过 Qwen Chat 体验，提到后续可能开源传闻。,data/raw/wechat/2026-02-11.md,1,from_ai_daily_primary_link
C00082,cmp_mosi-ai,MOSI.AI,daily_report_fact,text,MOSI.AI与OpenMOSS发布MOSS-TTS家族,2026-02-11,MOSI.AI与OpenMOSS发布MOSS-TTS家族,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,https://github.com/OpenMOSS/MOSS-TTS,primary,candidate,2026-02-12,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,data/raw/wechat/2026-02-11.md,2,from_ai_daily_primary_link
C00083,cpt_moss-soundeffect,MOSS-SoundEffect,daily_report_fact,text,MOSI.AI与OpenMOSS发布MOSS-TTS家族,2026-02-11,MOSI.AI与OpenMOSS发布MOSS-TTS家族,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,https://github.com/OpenMOSS/MOSS-TTS,primary,candidate,2026-02-12,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,data/raw/wechat/2026-02-11.md,2,from_ai_daily_primary_link
C00084,cpt_moss-tts,MOSS-TTS,daily_report_fact,text,MOSI.AI与OpenMOSS发布MOSS-TTS家族,2026-02-11,MOSI.AI与OpenMOSS发布MOSS-TTS家族,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,https://github.com/OpenMOSS/MOSS-TTS,primary,candidate,2026-02-12,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,data/raw/wechat/2026-02-11.md,2,from_ai_daily_primary_link
C00085,cpt_moss-tts-realtime,MOSS-TTS-Realtime,daily_report_fact,text,MOSI.AI与OpenMOSS发布MOSS-TTS家族,2026-02-11,MOSI.AI与OpenMOSS发布MOSS-TTS家族,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,https://github.com/OpenMOSS/MOSS-TTS,primary,candidate,2026-02-12,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,data/raw/wechat/2026-02-11.md,2,from_ai_daily_primary_link
C00086,cpt_moss-ttsd-v1-0,MOSS-TTSD v1.0,daily_report_fact,text,MOSI.AI与OpenMOSS发布MOSS-TTS家族,2026-02-11,MOSI.AI与OpenMOSS发布MOSS-TTS家族,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,https://github.com/OpenMOSS/MOSS-TTS,primary,candidate,2026-02-12,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,data/raw/wechat/2026-02-11.md,2,from_ai_daily_primary_link
C00087,cpt_moss-voicegenerator,MOSS-VoiceGenerator,daily_report_fact,text,MOSI.AI与OpenMOSS发布MOSS-TTS家族,2026-02-11,MOSI.AI与OpenMOSS发布MOSS-TTS家族,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,https://github.com/OpenMOSS/MOSS-TTS,primary,candidate,2026-02-12,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,data/raw/wechat/2026-02-11.md,2,from_ai_daily_primary_link
C00088,cpt_mossttsdelay,MossTTSDelay,daily_report_fact,text,MOSI.AI与OpenMOSS发布MOSS-TTS家族,2026-02-11,MOSI.AI与OpenMOSS发布MOSS-TTS家族,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,https://github.com/OpenMOSS/MOSS-TTS,primary,candidate,2026-02-12,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,data/raw/wechat/2026-02-11.md,2,from_ai_daily_primary_link
C00089,cpt_mossttslocal,MossTTSLocal,daily_report_fact,text,MOSI.AI与OpenMOSS发布MOSS-TTS家族,2026-02-11,MOSI.AI与OpenMOSS发布MOSS-TTS家族,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,https://github.com/OpenMOSS/MOSS-TTS,primary,candidate,2026-02-12,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,data/raw/wechat/2026-02-11.md,2,from_ai_daily_primary_link
C00090,cpt_openmoss,OpenMOSS,daily_report_fact,text,MOSI.AI与OpenMOSS发布MOSS-TTS家族,2026-02-11,MOSI.AI与OpenMOSS发布MOSS-TTS家族,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,https://github.com/OpenMOSS/MOSS-TTS,primary,candidate,2026-02-12,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,data/raw/wechat/2026-02-11.md,2,from_ai_daily_primary_link
C00091,cpt_llada2-1,LLaDA2.1,daily_report_fact,text,蚂蚁集团发布LLaDA2.1扩散大语言模型,2026-02-11,蚂蚁集团发布LLaDA2.1扩散大语言模型,LLaDA2.1 包含 16B（Mini）和 100B（Flash）版本，强调 Token-to-Token 编辑机制与 ECE 引擎，支持生成中实时纠错；文中提及复杂编码任务推理速度等指标，并给出权重与代码公开信息。,https://github.com/inclusionAI/LLaDA2.X,primary,candidate,2026-02-12,LLaDA2.1 包含 16B（Mini）和 100B（Flash）版本，强调 Token-to-Token 编辑机制与 ECE 引擎，支持生成中实时纠错；文中提及复杂编码任务推理速度等指标，并给出权重与代码公开信息。,data/raw/wechat/2026-02-11.md,3,from_ai_daily_primary_link
C00092,cpt_hunyuan-1-8b-instruct,Hunyuan-1.8B-Instruct,daily_report_fact,text,腾讯混元发布HY-1.8B-2Bit端侧量化模型,2026-02-11,腾讯混元发布HY-1.8B-2Bit端侧量化模型,基于 Hunyuan-1.8B-Instruct 的 2bit 量化模型，强调 QAT 路线、端侧速度提升、内存占用下降、在 MacBook M4 与天玑平台测试表现，含设备与部署限制说明。,https://huggingface.co/AngelSlim/HY-1.8B-2Bit,primary,candidate,2026-02-12,基于 Hunyuan-1.8B-Instruct 的 2bit 量化模型，强调 QAT 路线、端侧速度提升、内存占用下降、在 MacBook M4 与天玑平台测试表现，含设备与部署限制说明。,data/raw/wechat/2026-02-11.md,4,from_ai_daily_primary_link
C00093,cpt_hy-1-8b-2bit,HY-1.8B-2Bit,daily_report_fact,text,腾讯混元发布HY-1.8B-2Bit端侧量化模型,2026-02-11,腾讯混元发布HY-1.8B-2Bit端侧量化模型,基于 Hunyuan-1.8B-Instruct 的 2bit 量化模型，强调 QAT 路线、端侧速度提升、内存占用下降、在 MacBook M4 与天玑平台测试表现，含设备与部署限制说明。,https://huggingface.co/AngelSlim/HY-1.8B-2Bit,primary,candidate,2026-02-12,基于 Hunyuan-1.8B-Instruct 的 2bit 量化模型，强调 QAT 路线、端侧速度提升、内存占用下降、在 MacBook M4 与天玑平台测试表现，含设备与部署限制说明。,data/raw/wechat/2026-02-11.md,4,from_ai_daily_primary_link
C00094,cpt_gpt-5-2,GPT-5.2,daily_report_fact,text,OpenAI 将高风险 GPT-5.3-Codex 请求路由至 GPT-5.2,2026-02-11,OpenAI 将高风险 GPT-5.3-Codex 请求路由至 GPT-5.2,提到 OpenAI 针对高滥用风险请求进行自动路由降级处理，并计划提供更清晰的路由状态通知。,https://openai.com,primary,candidate,2026-02-12,提到 OpenAI 针对高滥用风险请求进行自动路由降级处理，并计划提供更清晰的路由状态通知。,data/raw/wechat/2026-02-11.md,5,from_ai_daily_primary_link
C00095,cpt_gpt-5-3-codex,GPT-5.3-Codex,daily_report_fact,text,OpenAI 将高风险 GPT-5.3-Codex 请求路由至 GPT-5.2,2026-02-11,OpenAI 将高风险 GPT-5.3-Codex 请求路由至 GPT-5.2,提到 OpenAI 针对高滥用风险请求进行自动路由降级处理，并计划提供更清晰的路由状态通知。,https://openai.com,primary,candidate,2026-02-12,提到 OpenAI 针对高滥用风险请求进行自动路由降级处理，并计划提供更清晰的路由状态通知。,data/raw/wechat/2026-02-11.md,5,from_ai_daily_primary_link
C00096,cmp_openai,OpenAI,daily_report_fact,text,OpenAI 将高风险 GPT-5.3-Codex 请求路由至 GPT-5.2,2026-02-11,OpenAI 将高风险 GPT-5.3-Codex 请求路由至 GPT-5.2,提到 OpenAI 针对高滥用风险请求进行自动路由降级处理，并计划提供更清晰的路由状态通知。,https://openai.com,primary,candidate,2026-02-12,提到 OpenAI 针对高滥用风险请求进行自动路由降级处理，并计划提供更清晰的路由状态通知。,data/raw/wechat/2026-02-11.md,5,from_ai_daily_primary_link
C00097,cmp_openai,OpenAI,daily_report_fact,text,OpenAI更新Responses API支持Agent任务,2026-02-11,OpenAI更新Responses API支持Agent任务,提到 Responses API 增加服务端压缩、托管容器受控网络访问、原生 Agent Skills（首发 spreadsheets skill）等能力。,https://developers.openai.com/api/docs/guides/tools-shell,primary,candidate,2026-02-12,提到 Responses API 增加服务端压缩、托管容器受控网络访问、原生 Agent Skills（首发 spreadsheets skill）等能力。,data/raw/wechat/2026-02-11.md,6,from_ai_daily_primary_link
C00098,cpt_responses-api,Responses API,daily_report_fact,text,OpenAI更新Responses API支持Agent任务,2026-02-11,OpenAI更新Responses API支持Agent任务,提到 Responses API 增加服务端压缩、托管容器受控网络访问、原生 Agent Skills（首发 spreadsheets skill）等能力。,https://developers.openai.com/api/docs/guides/tools-shell,primary,candidate,2026-02-12,提到 Responses API 增加服务端压缩、托管容器受控网络访问、原生 Agent Skills（首发 spreadsheets skill）等能力。,data/raw/wechat/2026-02-11.md,6,from_ai_daily_primary_link
C00099,cpt_oz,Oz,daily_report_fact,text,Warp推出Oz云原生Agent编排平台,2026-02-11,Warp推出Oz云原生Agent编排平台,Warp 发布 Oz，用于大规模运行、管理、审计和编排编码 Agent，支持 CLI/API/SDK/Web 入口。,https://www.warp.dev/blog/oz-orchestration-platform-cloud-agents,primary,candidate,2026-02-12,Warp 发布 Oz，用于大规模运行、管理、审计和编排编码 Agent，支持 CLI/API/SDK/Web 入口。,data/raw/wechat/2026-02-11.md,8,from_ai_daily_primary_link
C00100,cmp_warp,Warp,daily_report_fact,text,Warp推出Oz云原生Agent编排平台,2026-02-11,Warp推出Oz云原生Agent编排平台,Warp 发布 Oz，用于大规模运行、管理、审计和编排编码 Agent，支持 CLI/API/SDK/Web 入口。,https://www.warp.dev/blog/oz-orchestration-platform-cloud-agents,primary,candidate,2026-02-12,Warp 发布 Oz，用于大规模运行、管理、审计和编排编码 Agent，支持 CLI/API/SDK/Web 入口。,data/raw/wechat/2026-02-11.md,8,from_ai_daily_primary_link
C00101,cpt_gemini-skills,gemini-skills,daily_report_fact,text,Gemini 发布 Gemini API skills,2026-02-11,Gemini 发布 Gemini API skills,Google 在 GitHub 发布 `gemini-skills` 开源仓库（Apache-2.0），用于 Gemini API/SDK 交互实践。,https://github.com/google-gemini/gemini-skills,primary,candidate,2026-02-12,Google 在 GitHub 发布 `gemini-skills` 开源仓库（Apache-2.0），用于 Gemini API/SDK 交互实践。,data/raw/wechat/2026-02-11.md,10,from_ai_daily_primary_link
C00102,cmp_google,Google,daily_report_fact,text,Gemini 发布 Gemini API skills,2026-02-11,Gemini 发布 Gemini API skills,Google 在 GitHub 发布 `gemini-skills` 开源仓库（Apache-2.0），用于 Gemini API/SDK 交互实践。,https://github.com/google-gemini/gemini-skills,primary,candidate,2026-02-12,Google 在 GitHub 发布 `gemini-skills` 开源仓库（Apache-2.0），用于 Gemini API/SDK 交互实践。,data/raw/wechat/2026-02-11.md,10,from_ai_daily_primary_link
C00103,cmp_entire,Entire,daily_report_fact,text,Entire成立并获6000万美元种子融资,2026-02-11,Entire成立并获6000万美元种子融资,前 GitHub CEO Thomas Dohmke 创立 Entire，完成 6000 万美元种子轮融资（文中提估值 3 亿美元）。首款开源 CLI `Checkpoints` 聚焦把 AI Agent 会话纳入 Git 工作流。,https://github.com/entireio/cli,primary,candidate,2026-02-12,前 GitHub CEO Thomas Dohmke 创立 Entire，完成 6000 万美元种子轮融资（文中提估值 3 亿美元）。首款开源 CLI `Checkpoints` 聚焦把 AI Agent 会话纳入 Git 工作流。,data/raw/wechat/2026-02-11.md,11,from_ai_daily_primary_link
C00104,prs_thomas-dohmke,Thomas Dohmke,daily_report_fact,text,Entire成立并获6000万美元种子融资,2026-02-11,Entire成立并获6000万美元种子融资,前 GitHub CEO Thomas Dohmke 创立 Entire，完成 6000 万美元种子轮融资（文中提估值 3 亿美元）。首款开源 CLI `Checkpoints` 聚焦把 AI Agent 会话纳入 Git 工作流。,https://github.com/entireio/cli,primary,candidate,2026-02-12,前 GitHub CEO Thomas Dohmke 创立 Entire，完成 6000 万美元种子轮融资（文中提估值 3 亿美元）。首款开源 CLI `Checkpoints` 聚焦把 AI Agent 会话纳入 Git 工作流。,data/raw/wechat/2026-02-11.md,11,from_ai_daily_primary_link
C00105,cmp_obsidian,Obsidian,daily_report_fact,text,Obsidian发布Obsidian CLI,2026-02-11,Obsidian发布Obsidian CLI,Obsidian CLI Early Access，支持命令行与 TUI 方式管理笔记/任务/标签等，提及 Catalyst license 要求。,https://help.obsidian.md/cli,primary,candidate,2026-02-12,Obsidian CLI Early Access，支持命令行与 TUI 方式管理笔记/任务/标签等，提及 Catalyst license 要求。,data/raw/wechat/2026-02-11.md,17,from_ai_daily_primary_link
C00106,cpt_obsidian-cli,Obsidian CLI,daily_report_fact,text,Obsidian发布Obsidian CLI,2026-02-11,Obsidian发布Obsidian CLI,Obsidian CLI Early Access，支持命令行与 TUI 方式管理笔记/任务/标签等，提及 Catalyst license 要求。,https://help.obsidian.md/cli,primary,candidate,2026-02-12,Obsidian CLI Early Access，支持命令行与 TUI 方式管理笔记/任务/标签等，提及 Catalyst license 要求。,data/raw/wechat/2026-02-11.md,17,from_ai_daily_primary_link
C00107,cmp_runway,Runway,daily_report_fact,text,Runway完成3.15亿美元E轮融资,2026-02-11,Runway完成3.15亿美元E轮融资,Runway 完成 3.15 亿美元 E 轮，估值约 53 亿美元，资金指向下一代世界模型及产品扩展。,https://techcrunch.com/2026/02/10/ai-video-startup-runway-raises-315m-at-5-3b-valuation-eyes-more-capable-world-models,primary,candidate,2026-02-12,Runway 完成 3.15 亿美元 E 轮，估值约 53 亿美元，资金指向下一代世界模型及产品扩展。,data/raw/wechat/2026-02-11.md,19,from_ai_daily_primary_link
C00108,cmp_nebius,Nebius,daily_report_fact,text,Nebius收购Tavily,2026-02-11,Nebius收购Tavily,Nebius 宣布收购 agentic search 提供商 Tavily，目标增强 AI 云平台的实时网络验证能力。,https://nebius.com/newsroom/nebius-announces-agreement-to-acquire-tavily-to-add-agentic-search-to-its-ai-cloud-platform,primary,candidate,2026-02-12,Nebius 宣布收购 agentic search 提供商 Tavily，目标增强 AI 云平台的实时网络验证能力。,data/raw/wechat/2026-02-11.md,20,from_ai_daily_primary_link
C00109,cmp_tavily,Tavily,daily_report_fact,text,Nebius收购Tavily,2026-02-11,Nebius收购Tavily,Nebius 宣布收购 agentic search 提供商 Tavily，目标增强 AI 云平台的实时网络验证能力。,https://nebius.com/newsroom/nebius-announces-agreement-to-acquire-tavily-to-add-agentic-search-to-its-ai-cloud-platform,primary,candidate,2026-02-12,Nebius 宣布收购 agentic search 提供商 Tavily，目标增强 AI 云平台的实时网络验证能力。,data/raw/wechat/2026-02-11.md,20,from_ai_daily_primary_link
C00110,cmp_anthropic,Anthropic,daily_report_fact,text,Anthropic发布2026 Agent编程趋势报告,2026-02-11,Anthropic发布2026 Agent编程趋势报告,发布《2026 Agentic Coding Trends Report》，给出 Agent 编程趋势判断与角色迁移预测。,https://resources.anthropic.com/hubfs/2026%20Agentic%20Coding%20Trends%20Report.pdf?hsLang=en,primary,candidate,2026-02-12,发布《2026 Agentic Coding Trends Report》，给出 Agent 编程趋势判断与角色迁移预测。,data/raw/wechat/2026-02-11.md,21,from_ai_daily_primary_link
C00111,cmp_unsloth,Unsloth,daily_report_fact,text,Unsloth发布MoE训练优化,2026-02-11,Unsloth发布MoE训练优化,Unsloth 更新 MoE 训练优化，提到训练速度、显存节省与上下文扩展等指标。,https://unsloth.ai/docs/new/faster-moe,primary,candidate,2026-02-12,Unsloth 更新 MoE 训练优化，提到训练速度、显存节省与上下文扩展等指标。,data/raw/wechat/2026-02-11.md,22,from_ai_daily_primary_link
C00112,cpt_webmcp,WebMCP,daily_report_fact,text,Chrome 146 推出 WebMCP 早期预览,2026-02-11,Chrome 146 推出 WebMCP 早期预览,Chrome 146 引入 WebMCP 预览，允许 Agent 直接调用网站声明能力（实验状态，需启用 flag）。,https://docs.google.com/document/d/1rtU1fRPS0bMqd9abMG_hc6K9OAI6soUy3Kh00toAgyk/edit,primary,candidate,2026-02-12,Chrome 146 引入 WebMCP 预览，允许 Agent 直接调用网站声明能力（实验状态，需启用 flag）。,data/raw/wechat/2026-02-11.md,23,from_ai_daily_primary_link
C00113,cpt_glm-5,GLM-5,daily_report_fact,text,智谱AI发布并开源GLM-5模型,2026-02-12,智谱AI发布并开源GLM-5模型,智谱发布并开源 GLM-5（744B/激活40B），支持 200K 上下文，强调 coding 与 agent 能力，称在 SWE-bench-Verified 与 Terminal Bench 2.0 取得开源模型领先成绩，并已在官方产品线开放使用。,https://github.com/zai-org/GLM-5,primary,candidate,2026-02-12,智谱发布并开源 GLM-5（744B/激活40B），支持 200K 上下文，强调 coding 与 agent 能力，称在 SWE-bench-Verified 与 Terminal Bench 2.0 取得开源模型领先成绩，并已在官方产品线开放使用。,data/raw/wechat/2026-02-12.md,1,from_ai_daily_primary_link
C00114,cmp_minimax,MiniMax,daily_report_fact,text,MiniMax上线MiniMax M2.5,2026-02-12,MiniMax上线MiniMax M2.5,MiniMax 上线新旗舰模型 MiniMax M2.5，可在 Web 端和桌面端 MiniMax Agent 调用。,https://agent.minimax.io/,primary,candidate,2026-02-12,MiniMax 上线新旗舰模型 MiniMax M2.5，可在 Web 端和桌面端 MiniMax Agent 调用。,data/raw/wechat/2026-02-12.md,3,from_ai_daily_primary_link
C00115,cpt_minimax-m2-5,MiniMax M2.5,daily_report_fact,text,MiniMax上线MiniMax M2.5,2026-02-12,MiniMax上线MiniMax M2.5,MiniMax 上线新旗舰模型 MiniMax M2.5，可在 Web 端和桌面端 MiniMax Agent 调用。,https://agent.minimax.io/,primary,candidate,2026-02-12,MiniMax 上线新旗舰模型 MiniMax M2.5，可在 Web 端和桌面端 MiniMax Agent 调用。,data/raw/wechat/2026-02-12.md,3,from_ai_daily_primary_link
C00116,cpt_ming-flash-omni-2-0,Ming-flash-omni 2.0,daily_report_fact,text,蚂蚁集团发布全模态大模型Ming-flash-omni 2.0,2026-02-12,蚂蚁集团发布全模态大模型Ming-flash-omni 2.0,蚂蚁集团发布 Ming-flash-omni 2.0（Ling-2.0 架构），支持多模态认知、统一音频生成与图像处理，并开源发布。,https://huggingface.co/inclusionAI/Ming-flash-omni-2.0,primary,candidate,2026-02-12,蚂蚁集团发布 Ming-flash-omni 2.0（Ling-2.0 架构），支持多模态认知、统一音频生成与图像处理，并开源发布。,data/raw/wechat/2026-02-12.md,5,from_ai_daily_primary_link
C00117,cpt_minicpm-sala,MiniCPM-SALA,daily_report_fact,text,OpenBMB发布MiniCPM-SALA百万上下文模型,2026-02-12,OpenBMB发布MiniCPM-SALA百万上下文模型,OpenBMB 开源 MiniCPM-SALA（9B），采用混合稀疏与线性注意力机制，支持 1M 上下文。,https://huggingface.co/openbmb/MiniCPM-SALA,primary,candidate,2026-02-12,OpenBMB 开源 MiniCPM-SALA（9B），采用混合稀疏与线性注意力机制，支持 1M 上下文。,data/raw/wechat/2026-02-12.md,7,from_ai_daily_primary_link
C00118,cmp_openbmb,OpenBMB,daily_report_fact,text,OpenBMB发布MiniCPM-SALA百万上下文模型,2026-02-12,OpenBMB发布MiniCPM-SALA百万上下文模型,OpenBMB 开源 MiniCPM-SALA（9B），采用混合稀疏与线性注意力机制，支持 1M 上下文。,https://huggingface.co/openbmb/MiniCPM-SALA,primary,candidate,2026-02-12,OpenBMB 开源 MiniCPM-SALA（9B），采用混合稀疏与线性注意力机制，支持 1M 上下文。,data/raw/wechat/2026-02-12.md,7,from_ai_daily_primary_link
C00119,cpt_nanbeige4-1-3b,Nanbeige4.1-3B,daily_report_fact,text,BOSS直聘推出Nanbeige4.1-3B模型,2026-02-12,BOSS直聘推出Nanbeige4.1-3B模型,BOSS直聘 Nanbeige LLM Lab 开源 Nanbeige4.1-3B，强调推理、偏好对齐与 Agent 能力。,https://huggingface.co/Nanbeige/Nanbeige4.1-3B,primary,candidate,2026-02-12,BOSS直聘 Nanbeige LLM Lab 开源 Nanbeige4.1-3B，强调推理、偏好对齐与 Agent 能力。,data/raw/wechat/2026-02-12.md,8,from_ai_daily_primary_link
C00120,cmp_soul-ailab,Soul-AILab,daily_report_fact,text,Soul推出SoulX-Singer歌声合成模型,2026-02-12,Soul推出SoulX-Singer歌声合成模型,Soul-AILab 开源 SoulX-Singer，支持零样本歌声合成与多语言演唱。,https://arxiv.org/abs/2602.07803,primary,candidate,2026-02-12,Soul-AILab 开源 SoulX-Singer，支持零样本歌声合成与多语言演唱。,data/raw/wechat/2026-02-12.md,9,from_ai_daily_primary_link
C00121,cpt_soulx-singer,SoulX-Singer,daily_report_fact,text,Soul推出SoulX-Singer歌声合成模型,2026-02-12,Soul推出SoulX-Singer歌声合成模型,Soul-AILab 开源 SoulX-Singer，支持零样本歌声合成与多语言演唱。,https://arxiv.org/abs/2602.07803,primary,candidate,2026-02-12,Soul-AILab 开源 SoulX-Singer，支持零样本歌声合成与多语言演唱。,data/raw/wechat/2026-02-12.md,9,from_ai_daily_primary_link
C00122,cpt_z-code,Z Code,daily_report_fact,text,智谱正式发布AI编程工具 Z Code,2026-02-12,智谱正式发布AI编程工具 Z Code,智谱正式发布 Z Code，支持多 Agent 切换、内置浏览器、手机远程控制。,https://zcode-ai.com/,primary,candidate,2026-02-12,智谱正式发布 Z Code，支持多 Agent 切换、内置浏览器、手机远程控制。,data/raw/wechat/2026-02-12.md,10,from_ai_daily_primary_link
C00123,cpt_droid-agent,Droid Agent,daily_report_fact,text,Factory与JetBrains合作集成Droid Agent,2026-02-12,Factory与JetBrains合作集成Droid Agent,Factory 与 JetBrains 合作，Droid 可在 JetBrains IDE 通过 ACP 运行。,https://docs.google.com/forms/d/e/1FAIpQLSdCLNQ_0uPgRwOu7L4vhkPYhznK1cO7M5FyvrCOXUzOCkjabw/viewform,primary,candidate,2026-02-12,Factory 与 JetBrains 合作，Droid 可在 JetBrains IDE 通过 ACP 运行。,data/raw/wechat/2026-02-12.md,13,from_ai_daily_primary_link
C00124,cmp_factory,Factory,daily_report_fact,text,Factory与JetBrains合作集成Droid Agent,2026-02-12,Factory与JetBrains合作集成Droid Agent,Factory 与 JetBrains 合作，Droid 可在 JetBrains IDE 通过 ACP 运行。,https://docs.google.com/forms/d/e/1FAIpQLSdCLNQ_0uPgRwOu7L4vhkPYhznK1cO7M5FyvrCOXUzOCkjabw/viewform,primary,candidate,2026-02-12,Factory 与 JetBrains 合作，Droid 可在 JetBrains IDE 通过 ACP 运行。,data/raw/wechat/2026-02-12.md,13,from_ai_daily_primary_link
C00125,cmp_jetbrains,JetBrains,daily_report_fact,text,Factory与JetBrains合作集成Droid Agent,2026-02-12,Factory与JetBrains合作集成Droid Agent,Factory 与 JetBrains 合作，Droid 可在 JetBrains IDE 通过 ACP 运行。,https://docs.google.com/forms/d/e/1FAIpQLSdCLNQ_0uPgRwOu7L4vhkPYhznK1cO7M5FyvrCOXUzOCkjabw/viewform,primary,candidate,2026-02-12,Factory 与 JetBrains 合作，Droid 可在 JetBrains IDE 通过 ACP 运行。,data/raw/wechat/2026-02-12.md,13,from_ai_daily_primary_link
C00126,cpt_glm-in-excel,GLM in Excel,daily_report_fact,text,智谱发布GLM in Excel插件,2026-02-12,智谱发布GLM in Excel插件,智谱发布 GLM in Excel (Beta)，通过侧边栏在 Excel 中执行数据分析、图表与公式修复等任务。,https://docs.bigmodel.cn/cn/guide/tools/glm-in-excel,primary,candidate,2026-02-12,智谱发布 GLM in Excel (Beta)，通过侧边栏在 Excel 中执行数据分析、图表与公式修复等任务。,data/raw/wechat/2026-02-12.md,15,from_ai_daily_primary_link
C00127,cmp_mistral-ai,Mistral AI,daily_report_fact,text,Mistral AI投资12亿欧元瑞典数据中心,2026-02-12,Mistral AI投资12亿欧元瑞典数据中心,Mistral AI 宣布在瑞典投资建设数据中心，计划 2027 年启用。,https://www.reuters.com/sustainability/boards-policy-regulation/france-ai-company-mistral-invests-14-billion-data-centres-sweden-2026-02-11/,primary,candidate,2026-02-12,Mistral AI 宣布在瑞典投资建设数据中心，计划 2027 年启用。,data/raw/wechat/2026-02-12.md,18,from_ai_daily_primary_link
C00128,cmp_openai,OpenAI,daily_report_fact,text,OpenAI解散任务对齐团队,2026-02-12,OpenAI解散任务对齐团队,OpenAI 解散任务对齐团队并调整组织架构，团队成员转至其他岗位。,https://openaiglobalaffairs.substack.com/p/introducing-our-chief-futurist,primary,candidate,2026-02-12,OpenAI 解散任务对齐团队并调整组织架构，团队成员转至其他岗位。,data/raw/wechat/2026-02-12.md,19,from_ai_daily_primary_link
C00129,cmp_xai,xAI,daily_report_fact,text,xAI进行重组与人事变动,2026-02-12,xAI进行重组与人事变动,xAI 重组为四个产品团队（Grok、编码系统、Imagine、Macrohard），伴随人员流动。,https://techcrunch.com/2026/02/11/xai-lays-out-interplanetary-ambitions-in-public-all-hands,primary,candidate,2026-02-12,xAI 重组为四个产品团队（Grok、编码系统、Imagine、Macrohard），伴随人员流动。,data/raw/wechat/2026-02-12.md,20,from_ai_daily_primary_link
C00130,cmp_prime-intellect,Prime Intellect,daily_report_fact,text,Prime Intellect推出全栈agentic训练平台,2026-02-12,Prime Intellect推出全栈agentic训练平台,Prime Intellect 推出 Lab，覆盖 agentic post-training 的训练、评估与环境管理。,https://www.primeintellect.ai/blog/lab,primary,candidate,2026-02-12,Prime Intellect 推出 Lab，覆盖 agentic post-training 的训练、评估与环境管理。,data/raw/wechat/2026-02-12.md,21,from_ai_daily_primary_link
C00131,cpt_gemini-deep-think,Gemini Deep Think,daily_report_fact,text,Gemini Deep Think 攻克科研级难题,2026-02-12,Gemini Deep Think 攻克科研级难题,Google DeepMind 与 Google Research 发布 Gemini Deep Think 相关论文，展示数学/物理/计算机科学研究应用。,https://deepmind.google/blog/accelerating-mathematical-and-scientific-discovery-with-gemini-deep-think/,primary,candidate,2026-02-12,Google DeepMind 与 Google Research 发布 Gemini Deep Think 相关论文，展示数学/物理/计算机科学研究应用。,data/raw/wechat/2026-02-12.md,22,from_ai_daily_primary_link
C00132,cmp_google,Google,daily_report_fact,text,Gemini Deep Think 攻克科研级难题,2026-02-12,Gemini Deep Think 攻克科研级难题,Google DeepMind 与 Google Research 发布 Gemini Deep Think 相关论文，展示数学/物理/计算机科学研究应用。,https://deepmind.google/blog/accelerating-mathematical-and-scientific-discovery-with-gemini-deep-think/,primary,candidate,2026-02-12,Google DeepMind 与 Google Research 发布 Gemini Deep Think 相关论文，展示数学/物理/计算机科学研究应用。,data/raw/wechat/2026-02-12.md,22,from_ai_daily_primary_link
C00133,prs_andrej-karpathy,Andrej Karpathy,daily_report_fact,text,Karpathy开源243行纯 Python GPT 实现,2026-02-12,Karpathy开源243行纯 Python GPT 实现,Andrej Karpathy 发布 243 行纯 Python GPT 实现，用于展示最简核心算法。,https://gist.github.com/karpathy/8627fe009c40f57531cb18360106ce95,primary,candidate,2026-02-12,Andrej Karpathy 发布 243 行纯 Python GPT 实现，用于展示最简核心算法。,data/raw/wechat/2026-02-12.md,23,from_ai_daily_primary_link
C00134,cmp_anthropic,Anthropic,daily_report_fact,text,Anthropic发布Claude Opus 4.6破坏风险报告,2026-02-12,Anthropic发布Claude Opus 4.6破坏风险报告,Anthropic 发布 Claude Opus 4.6 sabotage risk report，结论为“非常低但不可忽略”。,https://anthropic.com/claude-opus-4-6-risk-report,primary,candidate,2026-02-12,Anthropic 发布 Claude Opus 4.6 sabotage risk report，结论为“非常低但不可忽略”。,data/raw/wechat/2026-02-12.md,24,from_ai_daily_primary_link
C00135,cpt_claude-opus-4-6,Claude Opus 4.6,daily_report_fact,text,Anthropic发布Claude Opus 4.6破坏风险报告,2026-02-12,Anthropic发布Claude Opus 4.6破坏风险报告,Anthropic 发布 Claude Opus 4.6 sabotage risk report，结论为“非常低但不可忽略”。,https://anthropic.com/claude-opus-4-6-risk-report,primary,candidate,2026-02-12,Anthropic 发布 Claude Opus 4.6 sabotage risk report，结论为“非常低但不可忽略”。,data/raw/wechat/2026-02-12.md,24,from_ai_daily_primary_link
C00136,cpt_codex-alpha,Codex Alpha,daily_report_fact,text,OpenAI开放Windows版Codex Alpha候补,2026-02-12,OpenAI开放Windows版Codex Alpha候补,OpenAI 开放 Codex Alpha Windows 版候补申请，Linux 版在计划中。,https://openai.com/form/codex-app/,primary,candidate,2026-02-12,OpenAI 开放 Codex Alpha Windows 版候补申请，Linux 版在计划中。,data/raw/wechat/2026-02-12.md,25,from_ai_daily_primary_link
C00137,cmp_openai,OpenAI,daily_report_fact,text,OpenAI开放Windows版Codex Alpha候补,2026-02-12,OpenAI开放Windows版Codex Alpha候补,OpenAI 开放 Codex Alpha Windows 版候补申请，Linux 版在计划中。,https://openai.com/form/codex-app/,primary,candidate,2026-02-12,OpenAI 开放 Codex Alpha Windows 版候补申请，Linux 版在计划中。,data/raw/wechat/2026-02-12.md,25,from_ai_daily_primary_link

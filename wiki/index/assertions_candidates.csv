candidate_id,subject_entity_id,subject_text,predicate,object_type,object_value,event_date,event_title,event_summary,source_url,source_type,status,last_updated,quote_span,raw_file,item_no,notes
C00001,,LongCat,daily_report_fact,text,美团推出LongCat-Flash-Lite模型,2026-02-07,美团推出LongCat-Flash-Lite模型,美团龙猫团队发布并开源 LongCat-Flash-Lite（68.5B MoE），强调高吞吐与 Agent/代码场景。,https://huggingface.co/meituan-longcat/LongCat-Flash-Lite,primary,candidate,2026-02-12,美团龙猫团队发布并开源 LongCat-Flash-Lite（68.5B MoE），强调高吞吐与 Agent/代码场景。,data/raw/wechat/2026-02-07.md,1,from_ai_daily_primary_link
C00002,,LongCat-Flash-Lite,daily_report_fact,text,美团推出LongCat-Flash-Lite模型,2026-02-07,美团推出LongCat-Flash-Lite模型,美团龙猫团队发布并开源 LongCat-Flash-Lite（68.5B MoE），强调高吞吐与 Agent/代码场景。,https://huggingface.co/meituan-longcat/LongCat-Flash-Lite,primary,candidate,2026-02-12,美团龙猫团队发布并开源 LongCat-Flash-Lite（68.5B MoE），强调高吞吐与 Agent/代码场景。,data/raw/wechat/2026-02-07.md,1,from_ai_daily_primary_link
C00003,,Seedance 2.0,daily_report_fact,text,字节跳动发布视频生成模型 Seedance 2.0,2026-02-07,字节跳动发布视频生成模型 Seedance 2.0,字节跳动发布 Seedance 2.0，支持图像/视频/音频/文本四模态输入生成 4-15 秒视频。,https://bytedance.larkoffice.com/wiki/A5RHwWhoBiOnjukIIw6cu5ybnXQ,primary,candidate,2026-02-12,字节跳动发布 Seedance 2.0，支持图像/视频/音频/文本四模态输入生成 4-15 秒视频。,data/raw/wechat/2026-02-07.md,2,from_ai_daily_primary_link
C00004,,Kilo Code,daily_report_fact,text,OpenRouter与Kilo Code上线 Pony Alpha 模型,2026-02-07,OpenRouter与Kilo Code上线 Pony Alpha 模型,OpenRouter 与 Kilo Code 上线 stealth 模型 Pony Alpha，强调 coding、reasoning 与 agentic workflows。,https://openrouter.ai/openrouter/pony-alpha,primary,candidate,2026-02-12,OpenRouter 与 Kilo Code 上线 stealth 模型 Pony Alpha，强调 coding、reasoning 与 agentic workflows。,data/raw/wechat/2026-02-07.md,3,from_ai_daily_primary_link
C00005,cmp_openrouter,OpenRouter,daily_report_fact,text,OpenRouter与Kilo Code上线 Pony Alpha 模型,2026-02-07,OpenRouter与Kilo Code上线 Pony Alpha 模型,OpenRouter 与 Kilo Code 上线 stealth 模型 Pony Alpha，强调 coding、reasoning 与 agentic workflows。,https://openrouter.ai/openrouter/pony-alpha,primary,candidate,2026-02-12,OpenRouter 与 Kilo Code 上线 stealth 模型 Pony Alpha，强调 coding、reasoning 与 agentic workflows。,data/raw/wechat/2026-02-07.md,3,from_ai_daily_primary_link
C00006,,Pony Alpha,daily_report_fact,text,OpenRouter与Kilo Code上线 Pony Alpha 模型,2026-02-07,OpenRouter与Kilo Code上线 Pony Alpha 模型,OpenRouter 与 Kilo Code 上线 stealth 模型 Pony Alpha，强调 coding、reasoning 与 agentic workflows。,https://openrouter.ai/openrouter/pony-alpha,primary,candidate,2026-02-12,OpenRouter 与 Kilo Code 上线 stealth 模型 Pony Alpha，强调 coding、reasoning 与 agentic workflows。,data/raw/wechat/2026-02-07.md,3,from_ai_daily_primary_link
C00007,,Waymo,daily_report_fact,text,Waymo推出Waymo World Model,2026-02-07,Waymo推出Waymo World Model,Waymo 推出基于 Genie 3 的 Waymo World Model，用于自动驾驶仿真训练。,https://waymo.com/blog/2026/02/the-waymo-world-model-a-new-frontier-for-autonomous-driving-simulation,primary,candidate,2026-02-12,Waymo 推出基于 Genie 3 的 Waymo World Model，用于自动驾驶仿真训练。,data/raw/wechat/2026-02-07.md,4,from_ai_daily_primary_link
C00008,,Waymo World Model,daily_report_fact,text,Waymo推出Waymo World Model,2026-02-07,Waymo推出Waymo World Model,Waymo 推出基于 Genie 3 的 Waymo World Model，用于自动驾驶仿真训练。,https://waymo.com/blog/2026/02/the-waymo-world-model-a-new-frontier-for-autonomous-driving-simulation,primary,candidate,2026-02-12,Waymo 推出基于 Genie 3 的 Waymo World Model，用于自动驾驶仿真训练。,data/raw/wechat/2026-02-07.md,4,from_ai_daily_primary_link
C00009,cmp_openai,OpenAI,daily_report_fact,text,OpenAI开放Sora真人角色视频生成功能,2026-02-07,OpenAI开放Sora真人角色视频生成功能,OpenAI 更新 Sora，支持真人角色图像生成视频与个性化角色创建。,https://help.openai.com/en/articles/12593142-sora-release-notes#image-2-video-with-people,primary,candidate,2026-02-12,OpenAI 更新 Sora，支持真人角色图像生成视频与个性化角色创建。,data/raw/wechat/2026-02-07.md,6,from_ai_daily_primary_link
C00010,,Sora,daily_report_fact,text,OpenAI开放Sora真人角色视频生成功能,2026-02-07,OpenAI开放Sora真人角色视频生成功能,OpenAI 更新 Sora，支持真人角色图像生成视频与个性化角色创建。,https://help.openai.com/en/articles/12593142-sora-release-notes#image-2-video-with-people,primary,candidate,2026-02-12,OpenAI 更新 Sora，支持真人角色图像生成视频与个性化角色创建。,data/raw/wechat/2026-02-07.md,6,from_ai_daily_primary_link
C00011,,Model Council,daily_report_fact,text,Perplexity推出多模型聚合问答功能,2026-02-07,Perplexity推出多模型聚合问答功能,Perplexity 推出 Model Council，单次查询并行调用多模型并输出综合答案。,https://www.perplexity.ai/hub/blog/introducing-model-council,primary,candidate,2026-02-12,Perplexity 推出 Model Council，单次查询并行调用多模型并输出综合答案。,data/raw/wechat/2026-02-07.md,7,from_ai_daily_primary_link
C00012,,Perplexity,daily_report_fact,text,Perplexity推出多模型聚合问答功能,2026-02-07,Perplexity推出多模型聚合问答功能,Perplexity 推出 Model Council，单次查询并行调用多模型并输出综合答案。,https://www.perplexity.ai/hub/blog/introducing-model-council,primary,candidate,2026-02-12,Perplexity 推出 Model Council，单次查询并行调用多模型并输出综合答案。,data/raw/wechat/2026-02-07.md,7,from_ai_daily_primary_link
C00013,cmp_anthropic,Anthropic,daily_report_fact,text,Anthropic推出Claude Opus 4.6快速模式,2026-02-08,Anthropic推出Claude Opus 4.6快速模式,Anthropic 为 Claude Opus 4.6 推出 fast mode，称速度约提升 2.5 倍，采用分档 token 定价并提供限时折扣。,https://code.claude.com/docs/en/fast-mode,primary,candidate,2026-02-12,Anthropic 为 Claude Opus 4.6 推出 fast mode，称速度约提升 2.5 倍，采用分档 token 定价并提供限时折扣。,data/raw/wechat/2026-02-08.md,1,from_ai_daily_primary_link
C00014,cpt_claude-opus-4-6,Claude Opus 4.6,daily_report_fact,text,Anthropic推出Claude Opus 4.6快速模式,2026-02-08,Anthropic推出Claude Opus 4.6快速模式,Anthropic 为 Claude Opus 4.6 推出 fast mode，称速度约提升 2.5 倍，采用分档 token 定价并提供限时折扣。,https://code.claude.com/docs/en/fast-mode,primary,candidate,2026-02-12,Anthropic 为 Claude Opus 4.6 推出 fast mode，称速度约提升 2.5 倍，采用分档 token 定价并提供限时折扣。,data/raw/wechat/2026-02-08.md,1,from_ai_daily_primary_link
C00015,,Augment Code,daily_report_fact,text,Augment Code正式上线Context Engine MCP,2026-02-08,Augment Code正式上线Context Engine MCP,Augment Code 宣布 Context Engine MCP 结束测试并正式上线，面向 MCP 兼容 AI 编码工具。,https://www.augmentcode.com/blog/context-engine-mcp-now-live,primary,candidate,2026-02-12,Augment Code 宣布 Context Engine MCP 结束测试并正式上线，面向 MCP 兼容 AI 编码工具。,data/raw/wechat/2026-02-08.md,2,from_ai_daily_primary_link
C00016,,Context Engine MCP,daily_report_fact,text,Augment Code正式上线Context Engine MCP,2026-02-08,Augment Code正式上线Context Engine MCP,Augment Code 宣布 Context Engine MCP 结束测试并正式上线，面向 MCP 兼容 AI 编码工具。,https://www.augmentcode.com/blog/context-engine-mcp-now-live,primary,candidate,2026-02-12,Augment Code 宣布 Context Engine MCP 结束测试并正式上线，面向 MCP 兼容 AI 编码工具。,data/raw/wechat/2026-02-08.md,2,from_ai_daily_primary_link
C00017,,Brendan Gregg,daily_report_fact,text,OpenAI引入性能专家优化数据中心成本,2026-02-08,OpenAI引入性能专家优化数据中心成本,性能专家 Brendan Gregg 加入 OpenAI ChatGPT 性能工程团队，聚焦数据中心效率与成本优化。,https://www.brendangregg.com/blog/2026-02-07/why-i-joined-openai.html,primary,candidate,2026-02-12,性能专家 Brendan Gregg 加入 OpenAI ChatGPT 性能工程团队，聚焦数据中心效率与成本优化。,data/raw/wechat/2026-02-08.md,3,from_ai_daily_primary_link
C00018,cmp_openai,OpenAI,daily_report_fact,text,OpenAI引入性能专家优化数据中心成本,2026-02-08,OpenAI引入性能专家优化数据中心成本,性能专家 Brendan Gregg 加入 OpenAI ChatGPT 性能工程团队，聚焦数据中心效率与成本优化。,https://www.brendangregg.com/blog/2026-02-07/why-i-joined-openai.html,primary,candidate,2026-02-12,性能专家 Brendan Gregg 加入 OpenAI ChatGPT 性能工程团队，聚焦数据中心效率与成本优化。,data/raw/wechat/2026-02-08.md,3,from_ai_daily_primary_link
C00019,cmp_openai,OpenAI,daily_report_fact,text,OpenAI 推进AI模型本土化策略,2026-02-08,OpenAI 推进AI模型本土化策略,OpenAI 推进本地化方案（OpenAI for Countries），包含爱沙尼亚与阿联酋相关项目。,https://openai.com/index/our-approach-to-localization/,primary,candidate,2026-02-12,OpenAI 推进本地化方案（OpenAI for Countries），包含爱沙尼亚与阿联酋相关项目。,data/raw/wechat/2026-02-08.md,4,from_ai_daily_primary_link
C00020,,OpenAI for Countries,daily_report_fact,text,OpenAI 推进AI模型本土化策略,2026-02-08,OpenAI 推进AI模型本土化策略,OpenAI 推进本地化方案（OpenAI for Countries），包含爱沙尼亚与阿联酋相关项目。,https://openai.com/index/our-approach-to-localization/,primary,candidate,2026-02-12,OpenAI 推进本地化方案（OpenAI for Countries），包含爱沙尼亚与阿联酋相关项目。,data/raw/wechat/2026-02-08.md,4,from_ai_daily_primary_link
C00021,,PLawBench,daily_report_fact,text,千问Qwen等联合推出法律评测基准PLawBench,2026-02-08,千问Qwen等联合推出法律评测基准PLawBench,Qwen 团队联合发布法律评测基准 PLawBench，覆盖法律咨询、案例分析与文书生成。,https://arxiv.org/abs/2601.16669,primary,candidate,2026-02-12,Qwen 团队联合发布法律评测基准 PLawBench，覆盖法律咨询、案例分析与文书生成。,data/raw/wechat/2026-02-08.md,5,from_ai_daily_primary_link
C00022,,CarPlay,daily_report_fact,text,苹果计划为CarPlay引入第三方AI语音,2026-02-08,苹果计划为CarPlay引入第三方AI语音,外媒报道苹果计划为 CarPlay 引入第三方 AI 语音助手支持。,https://www.bloomberg.com/news/articles/2026-02-06/apple-plans-to-allow-outside-voice-controlled-ai-chatbots-in-carplay,primary,candidate,2026-02-12,外媒报道苹果计划为 CarPlay 引入第三方 AI 语音助手支持。,data/raw/wechat/2026-02-08.md,6,from_ai_daily_primary_link
C00023,cmp_openai,OpenAI,daily_report_fact,text,OpenAI正式启动ChatGPT广告测试,2026-02-10,OpenAI正式启动ChatGPT广告测试,OpenAI 在美国面向 Free 与 Go 部分成年用户测试 ChatGPT 广告，强调广告与回答视觉分离、敏感话题不投放、广告商无法获取聊天内容。支持关闭广告但会影响每日免费对话次数。,https://openai.com/index/testing-ads-in-chatgpt/,primary,candidate,2026-02-12,OpenAI 在美国面向 Free 与 Go 部分成年用户测试 ChatGPT 广告，强调广告与回答视觉分离、敏感话题不投放、广告商无法获取聊天内容。支持关闭广告但会影响每日免费对话次数。,data/raw/wechat/2026-02-10.md,1,from_ai_daily_primary_link
C00024,cpt_aurora-alpha,Aurora Alpha,daily_report_fact,text,OpenRouter上线 stealth 模型 Aurora Alpha,2026-02-10,OpenRouter上线 stealth 模型 Aurora Alpha,Aurora Alpha 面向编码助手、实时对话和 agentic workflow，支持 128k 上下文与高输出长度，支持 reasoning 参数。,https://openrouter.ai/openrouter/aurora-alpha,primary,candidate,2026-02-12,Aurora Alpha 面向编码助手、实时对话和 agentic workflow，支持 128k 上下文与高输出长度，支持 reasoning 参数。,data/raw/wechat/2026-02-10.md,3,from_ai_daily_primary_link
C00025,cmp_openrouter,OpenRouter,daily_report_fact,text,OpenRouter上线 stealth 模型 Aurora Alpha,2026-02-10,OpenRouter上线 stealth 模型 Aurora Alpha,Aurora Alpha 面向编码助手、实时对话和 agentic workflow，支持 128k 上下文与高输出长度，支持 reasoning 参数。,https://openrouter.ai/openrouter/aurora-alpha,primary,candidate,2026-02-12,Aurora Alpha 面向编码助手、实时对话和 agentic workflow，支持 128k 上下文与高输出长度，支持 reasoning 参数。,data/raw/wechat/2026-02-10.md,3,from_ai_daily_primary_link
C00026,cpt_composer-1-5,Composer 1.5,daily_report_fact,text,Cursor 上线编程模型 Composer 1.5,2026-02-10,Cursor 上线编程模型 Composer 1.5,Cursor 发布 Composer 1.5，描述为在同基座模型上通过更大规模强化学习得到提升，强调思考 token、自我总结和长任务处理能力。,https://cursor.com/cn/blog/composer-1-5,primary,candidate,2026-02-12,Cursor 发布 Composer 1.5，描述为在同基座模型上通过更大规模强化学习得到提升，强调思考 token、自我总结和长任务处理能力。,data/raw/wechat/2026-02-10.md,4,from_ai_daily_primary_link
C00027,cmp_cursor,Cursor,daily_report_fact,text,Cursor 上线编程模型 Composer 1.5,2026-02-10,Cursor 上线编程模型 Composer 1.5,Cursor 发布 Composer 1.5，描述为在同基座模型上通过更大规模强化学习得到提升，强调思考 token、自我总结和长任务处理能力。,https://cursor.com/cn/blog/composer-1-5,primary,candidate,2026-02-12,Cursor 发布 Composer 1.5，描述为在同基座模型上通过更大规模强化学习得到提升，强调思考 token、自我总结和长任务处理能力。,data/raw/wechat/2026-02-10.md,4,from_ai_daily_primary_link
C00028,cmp_hugging-face,Hugging Face,daily_report_fact,text,Hugging Face发布Transformers.js v4预览版,2026-02-10,Hugging Face发布Transformers.js v4预览版,Transformers.js v4 预览版引入 C++ 重写 WebGPU Runtime，支持更多模型架构与跨环境运行（浏览器/Node/Bun/Deno 等）。,https://huggingface.co/blog/transformersjs-v4,primary,candidate,2026-02-12,Transformers.js v4 预览版引入 C++ 重写 WebGPU Runtime，支持更多模型架构与跨环境运行（浏览器/Node/Bun/Deno 等）。,data/raw/wechat/2026-02-10.md,7,from_ai_daily_primary_link
C00029,cpt_transformers-js-v4,Transformers.js v4,daily_report_fact,text,Hugging Face发布Transformers.js v4预览版,2026-02-10,Hugging Face发布Transformers.js v4预览版,Transformers.js v4 预览版引入 C++ 重写 WebGPU Runtime，支持更多模型架构与跨环境运行（浏览器/Node/Bun/Deno 等）。,https://huggingface.co/blog/transformersjs-v4,primary,candidate,2026-02-12,Transformers.js v4 预览版引入 C++ 重写 WebGPU Runtime，支持更多模型架构与跨环境运行（浏览器/Node/Bun/Deno 等）。,data/raw/wechat/2026-02-10.md,7,from_ai_daily_primary_link
C00030,cpt_dsa,DSA,daily_report_fact,text,智谱GLM-5架构细节曝光总参数或达700B,2026-02-10,智谱GLM-5架构细节曝光总参数或达700B,提到 GLM-5 适配提交、DSA/MTP 技术线索、参数规模推测与上下文长度相关信息，属于前瞻传闻类条目。,https://github.com/huggingface/transformers/pull/43858,primary,candidate,2026-02-12,提到 GLM-5 适配提交、DSA/MTP 技术线索、参数规模推测与上下文长度相关信息，属于前瞻传闻类条目。,data/raw/wechat/2026-02-10.md,10,from_ai_daily_primary_link
C00031,cpt_glm-5,GLM-5,daily_report_fact,text,智谱GLM-5架构细节曝光总参数或达700B,2026-02-10,智谱GLM-5架构细节曝光总参数或达700B,提到 GLM-5 适配提交、DSA/MTP 技术线索、参数规模推测与上下文长度相关信息，属于前瞻传闻类条目。,https://github.com/huggingface/transformers/pull/43858,primary,candidate,2026-02-12,提到 GLM-5 适配提交、DSA/MTP 技术线索、参数规模推测与上下文长度相关信息，属于前瞻传闻类条目。,data/raw/wechat/2026-02-10.md,10,from_ai_daily_primary_link
C00032,cpt_mtp,MTP,daily_report_fact,text,智谱GLM-5架构细节曝光总参数或达700B,2026-02-10,智谱GLM-5架构细节曝光总参数或达700B,提到 GLM-5 适配提交、DSA/MTP 技术线索、参数规模推测与上下文长度相关信息，属于前瞻传闻类条目。,https://github.com/huggingface/transformers/pull/43858,primary,candidate,2026-02-12,提到 GLM-5 适配提交、DSA/MTP 技术线索、参数规模推测与上下文长度相关信息，属于前瞻传闻类条目。,data/raw/wechat/2026-02-10.md,10,from_ai_daily_primary_link
C00033,cpt_qwen-image-2-0,Qwen-Image-2.0,daily_report_fact,text,千问推出Qwen-Image-2.0统一图像模型,2026-02-11,千问推出Qwen-Image-2.0统一图像模型,千问团队发布 Qwen-Image-2.0，统一图像生成与编辑能力，支持 2K 分辨率和长指令，强调专业文字渲染、真实质感、多子图一致性等能力；已在阿里云百炼开放 API，可通过 Qwen Chat 体验，提到后续可能开源传闻。,https://qwen.ai/blog?id=qwen-image-2.0,primary,candidate,2026-02-12,千问团队发布 Qwen-Image-2.0，统一图像生成与编辑能力，支持 2K 分辨率和长指令，强调专业文字渲染、真实质感、多子图一致性等能力；已在阿里云百炼开放 API，可通过 Qwen Chat 体验，提到后续可能开源传闻。,data/raw/wechat/2026-02-11.md,1,from_ai_daily_primary_link
C00034,cmp_mosi-ai,MOSI.AI,daily_report_fact,text,MOSI.AI与OpenMOSS发布MOSS-TTS家族,2026-02-11,MOSI.AI与OpenMOSS发布MOSS-TTS家族,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,https://github.com/OpenMOSS/MOSS-TTS,primary,candidate,2026-02-12,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,data/raw/wechat/2026-02-11.md,2,from_ai_daily_primary_link
C00035,cpt_moss-soundeffect,MOSS-SoundEffect,daily_report_fact,text,MOSI.AI与OpenMOSS发布MOSS-TTS家族,2026-02-11,MOSI.AI与OpenMOSS发布MOSS-TTS家族,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,https://github.com/OpenMOSS/MOSS-TTS,primary,candidate,2026-02-12,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,data/raw/wechat/2026-02-11.md,2,from_ai_daily_primary_link
C00036,cpt_moss-tts,MOSS-TTS,daily_report_fact,text,MOSI.AI与OpenMOSS发布MOSS-TTS家族,2026-02-11,MOSI.AI与OpenMOSS发布MOSS-TTS家族,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,https://github.com/OpenMOSS/MOSS-TTS,primary,candidate,2026-02-12,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,data/raw/wechat/2026-02-11.md,2,from_ai_daily_primary_link
C00037,cpt_moss-tts-realtime,MOSS-TTS-Realtime,daily_report_fact,text,MOSI.AI与OpenMOSS发布MOSS-TTS家族,2026-02-11,MOSI.AI与OpenMOSS发布MOSS-TTS家族,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,https://github.com/OpenMOSS/MOSS-TTS,primary,candidate,2026-02-12,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,data/raw/wechat/2026-02-11.md,2,from_ai_daily_primary_link
C00038,cpt_moss-ttsd-v1-0,MOSS-TTSD v1.0,daily_report_fact,text,MOSI.AI与OpenMOSS发布MOSS-TTS家族,2026-02-11,MOSI.AI与OpenMOSS发布MOSS-TTS家族,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,https://github.com/OpenMOSS/MOSS-TTS,primary,candidate,2026-02-12,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,data/raw/wechat/2026-02-11.md,2,from_ai_daily_primary_link
C00039,cpt_moss-voicegenerator,MOSS-VoiceGenerator,daily_report_fact,text,MOSI.AI与OpenMOSS发布MOSS-TTS家族,2026-02-11,MOSI.AI与OpenMOSS发布MOSS-TTS家族,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,https://github.com/OpenMOSS/MOSS-TTS,primary,candidate,2026-02-12,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,data/raw/wechat/2026-02-11.md,2,from_ai_daily_primary_link
C00040,cpt_mossttsdelay,MossTTSDelay,daily_report_fact,text,MOSI.AI与OpenMOSS发布MOSS-TTS家族,2026-02-11,MOSI.AI与OpenMOSS发布MOSS-TTS家族,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,https://github.com/OpenMOSS/MOSS-TTS,primary,candidate,2026-02-12,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,data/raw/wechat/2026-02-11.md,2,from_ai_daily_primary_link
C00041,cpt_mossttslocal,MossTTSLocal,daily_report_fact,text,MOSI.AI与OpenMOSS发布MOSS-TTS家族,2026-02-11,MOSI.AI与OpenMOSS发布MOSS-TTS家族,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,https://github.com/OpenMOSS/MOSS-TTS,primary,candidate,2026-02-12,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,data/raw/wechat/2026-02-11.md,2,from_ai_daily_primary_link
C00042,cpt_openmoss,OpenMOSS,daily_report_fact,text,MOSI.AI与OpenMOSS发布MOSS-TTS家族,2026-02-11,MOSI.AI与OpenMOSS发布MOSS-TTS家族,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,https://github.com/OpenMOSS/MOSS-TTS,primary,candidate,2026-02-12,发布开源语音模型家族 MOSS-TTS（Apache-2.0），包含 MossTTSDelay、MossTTSLocal、MOSS-TTSD v1.0、MOSS-VoiceGenerator、MOSS-TTS-Realtime、MOSS-SoundEffect 等能力线，强调高保真、多说话人对话、实时语音体与音效生成。,data/raw/wechat/2026-02-11.md,2,from_ai_daily_primary_link
C00043,cpt_llada2-1,LLaDA2.1,daily_report_fact,text,蚂蚁集团发布LLaDA2.1扩散大语言模型,2026-02-11,蚂蚁集团发布LLaDA2.1扩散大语言模型,LLaDA2.1 包含 16B（Mini）和 100B（Flash）版本，强调 Token-to-Token 编辑机制与 ECE 引擎，支持生成中实时纠错；文中提及复杂编码任务推理速度等指标，并给出权重与代码公开信息。,https://github.com/inclusionAI/LLaDA2.X,primary,candidate,2026-02-12,LLaDA2.1 包含 16B（Mini）和 100B（Flash）版本，强调 Token-to-Token 编辑机制与 ECE 引擎，支持生成中实时纠错；文中提及复杂编码任务推理速度等指标，并给出权重与代码公开信息。,data/raw/wechat/2026-02-11.md,3,from_ai_daily_primary_link
C00044,cpt_hunyuan-1-8b-instruct,Hunyuan-1.8B-Instruct,daily_report_fact,text,腾讯混元发布HY-1.8B-2Bit端侧量化模型,2026-02-11,腾讯混元发布HY-1.8B-2Bit端侧量化模型,基于 Hunyuan-1.8B-Instruct 的 2bit 量化模型，强调 QAT 路线、端侧速度提升、内存占用下降、在 MacBook M4 与天玑平台测试表现，含设备与部署限制说明。,https://huggingface.co/AngelSlim/HY-1.8B-2Bit,primary,candidate,2026-02-12,基于 Hunyuan-1.8B-Instruct 的 2bit 量化模型，强调 QAT 路线、端侧速度提升、内存占用下降、在 MacBook M4 与天玑平台测试表现，含设备与部署限制说明。,data/raw/wechat/2026-02-11.md,4,from_ai_daily_primary_link
C00045,cpt_hy-1-8b-2bit,HY-1.8B-2Bit,daily_report_fact,text,腾讯混元发布HY-1.8B-2Bit端侧量化模型,2026-02-11,腾讯混元发布HY-1.8B-2Bit端侧量化模型,基于 Hunyuan-1.8B-Instruct 的 2bit 量化模型，强调 QAT 路线、端侧速度提升、内存占用下降、在 MacBook M4 与天玑平台测试表现，含设备与部署限制说明。,https://huggingface.co/AngelSlim/HY-1.8B-2Bit,primary,candidate,2026-02-12,基于 Hunyuan-1.8B-Instruct 的 2bit 量化模型，强调 QAT 路线、端侧速度提升、内存占用下降、在 MacBook M4 与天玑平台测试表现，含设备与部署限制说明。,data/raw/wechat/2026-02-11.md,4,from_ai_daily_primary_link
C00046,cpt_gpt-5-2,GPT-5.2,daily_report_fact,text,OpenAI 将高风险 GPT-5.3-Codex 请求路由至 GPT-5.2,2026-02-11,OpenAI 将高风险 GPT-5.3-Codex 请求路由至 GPT-5.2,提到 OpenAI 针对高滥用风险请求进行自动路由降级处理，并计划提供更清晰的路由状态通知。,http://chatgpt.com/cyber,primary,candidate,2026-02-12,提到 OpenAI 针对高滥用风险请求进行自动路由降级处理，并计划提供更清晰的路由状态通知。,data/raw/wechat/2026-02-11.md,5,from_ai_daily_primary_link
C00047,cpt_gpt-5-3-codex,GPT-5.3-Codex,daily_report_fact,text,OpenAI 将高风险 GPT-5.3-Codex 请求路由至 GPT-5.2,2026-02-11,OpenAI 将高风险 GPT-5.3-Codex 请求路由至 GPT-5.2,提到 OpenAI 针对高滥用风险请求进行自动路由降级处理，并计划提供更清晰的路由状态通知。,http://chatgpt.com/cyber,primary,candidate,2026-02-12,提到 OpenAI 针对高滥用风险请求进行自动路由降级处理，并计划提供更清晰的路由状态通知。,data/raw/wechat/2026-02-11.md,5,from_ai_daily_primary_link
C00048,cmp_openai,OpenAI,daily_report_fact,text,OpenAI 将高风险 GPT-5.3-Codex 请求路由至 GPT-5.2,2026-02-11,OpenAI 将高风险 GPT-5.3-Codex 请求路由至 GPT-5.2,提到 OpenAI 针对高滥用风险请求进行自动路由降级处理，并计划提供更清晰的路由状态通知。,http://chatgpt.com/cyber,primary,candidate,2026-02-12,提到 OpenAI 针对高滥用风险请求进行自动路由降级处理，并计划提供更清晰的路由状态通知。,data/raw/wechat/2026-02-11.md,5,from_ai_daily_primary_link
C00049,cmp_openai,OpenAI,daily_report_fact,text,OpenAI更新Responses API支持Agent任务,2026-02-11,OpenAI更新Responses API支持Agent任务,提到 Responses API 增加服务端压缩、托管容器受控网络访问、原生 Agent Skills（首发 spreadsheets skill）等能力。,https://developers.openai.com/api/docs/guides/tools-shell,primary,candidate,2026-02-12,提到 Responses API 增加服务端压缩、托管容器受控网络访问、原生 Agent Skills（首发 spreadsheets skill）等能力。,data/raw/wechat/2026-02-11.md,6,from_ai_daily_primary_link
C00050,cpt_responses-api,Responses API,daily_report_fact,text,OpenAI更新Responses API支持Agent任务,2026-02-11,OpenAI更新Responses API支持Agent任务,提到 Responses API 增加服务端压缩、托管容器受控网络访问、原生 Agent Skills（首发 spreadsheets skill）等能力。,https://developers.openai.com/api/docs/guides/tools-shell,primary,candidate,2026-02-12,提到 Responses API 增加服务端压缩、托管容器受控网络访问、原生 Agent Skills（首发 spreadsheets skill）等能力。,data/raw/wechat/2026-02-11.md,6,from_ai_daily_primary_link
C00051,cpt_oz,Oz,daily_report_fact,text,Warp推出Oz云原生Agent编排平台,2026-02-11,Warp推出Oz云原生Agent编排平台,Warp 发布 Oz，用于大规模运行、管理、审计和编排编码 Agent，支持 CLI/API/SDK/Web 入口。,https://www.warp.dev/blog/oz-orchestration-platform-cloud-agents,primary,candidate,2026-02-12,Warp 发布 Oz，用于大规模运行、管理、审计和编排编码 Agent，支持 CLI/API/SDK/Web 入口。,data/raw/wechat/2026-02-11.md,8,from_ai_daily_primary_link
C00052,cmp_warp,Warp,daily_report_fact,text,Warp推出Oz云原生Agent编排平台,2026-02-11,Warp推出Oz云原生Agent编排平台,Warp 发布 Oz，用于大规模运行、管理、审计和编排编码 Agent，支持 CLI/API/SDK/Web 入口。,https://www.warp.dev/blog/oz-orchestration-platform-cloud-agents,primary,candidate,2026-02-12,Warp 发布 Oz，用于大规模运行、管理、审计和编排编码 Agent，支持 CLI/API/SDK/Web 入口。,data/raw/wechat/2026-02-11.md,8,from_ai_daily_primary_link
C00053,cpt_gemini-skills,gemini-skills,daily_report_fact,text,Gemini 发布 Gemini API skills,2026-02-11,Gemini 发布 Gemini API skills,Google 在 GitHub 发布 `gemini-skills` 开源仓库（Apache-2.0），用于 Gemini API/SDK 交互实践。,https://github.com/google-gemini/gemini-skills,primary,candidate,2026-02-12,Google 在 GitHub 发布 `gemini-skills` 开源仓库（Apache-2.0），用于 Gemini API/SDK 交互实践。,data/raw/wechat/2026-02-11.md,10,from_ai_daily_primary_link
C00054,cmp_google,Google,daily_report_fact,text,Gemini 发布 Gemini API skills,2026-02-11,Gemini 发布 Gemini API skills,Google 在 GitHub 发布 `gemini-skills` 开源仓库（Apache-2.0），用于 Gemini API/SDK 交互实践。,https://github.com/google-gemini/gemini-skills,primary,candidate,2026-02-12,Google 在 GitHub 发布 `gemini-skills` 开源仓库（Apache-2.0），用于 Gemini API/SDK 交互实践。,data/raw/wechat/2026-02-11.md,10,from_ai_daily_primary_link
C00055,cmp_entire,Entire,daily_report_fact,text,Entire成立并获6000万美元种子融资,2026-02-11,Entire成立并获6000万美元种子融资,前 GitHub CEO Thomas Dohmke 创立 Entire，完成 6000 万美元种子轮融资（文中提估值 3 亿美元）。首款开源 CLI `Checkpoints` 聚焦把 AI Agent 会话纳入 Git 工作流。,https://github.com/entireio/cli,primary,candidate,2026-02-12,前 GitHub CEO Thomas Dohmke 创立 Entire，完成 6000 万美元种子轮融资（文中提估值 3 亿美元）。首款开源 CLI `Checkpoints` 聚焦把 AI Agent 会话纳入 Git 工作流。,data/raw/wechat/2026-02-11.md,11,from_ai_daily_primary_link
C00056,prs_thomas-dohmke,Thomas Dohmke,daily_report_fact,text,Entire成立并获6000万美元种子融资,2026-02-11,Entire成立并获6000万美元种子融资,前 GitHub CEO Thomas Dohmke 创立 Entire，完成 6000 万美元种子轮融资（文中提估值 3 亿美元）。首款开源 CLI `Checkpoints` 聚焦把 AI Agent 会话纳入 Git 工作流。,https://github.com/entireio/cli,primary,candidate,2026-02-12,前 GitHub CEO Thomas Dohmke 创立 Entire，完成 6000 万美元种子轮融资（文中提估值 3 亿美元）。首款开源 CLI `Checkpoints` 聚焦把 AI Agent 会话纳入 Git 工作流。,data/raw/wechat/2026-02-11.md,11,from_ai_daily_primary_link
C00057,cmp_obsidian,Obsidian,daily_report_fact,text,Obsidian发布Obsidian CLI,2026-02-11,Obsidian发布Obsidian CLI,Obsidian CLI Early Access，支持命令行与 TUI 方式管理笔记/任务/标签等，提及 Catalyst license 要求。,https://help.obsidian.md/cli,primary,candidate,2026-02-12,Obsidian CLI Early Access，支持命令行与 TUI 方式管理笔记/任务/标签等，提及 Catalyst license 要求。,data/raw/wechat/2026-02-11.md,17,from_ai_daily_primary_link
C00058,cpt_obsidian-cli,Obsidian CLI,daily_report_fact,text,Obsidian发布Obsidian CLI,2026-02-11,Obsidian发布Obsidian CLI,Obsidian CLI Early Access，支持命令行与 TUI 方式管理笔记/任务/标签等，提及 Catalyst license 要求。,https://help.obsidian.md/cli,primary,candidate,2026-02-12,Obsidian CLI Early Access，支持命令行与 TUI 方式管理笔记/任务/标签等，提及 Catalyst license 要求。,data/raw/wechat/2026-02-11.md,17,from_ai_daily_primary_link
C00059,cmp_runway,Runway,daily_report_fact,text,Runway完成3.15亿美元E轮融资,2026-02-11,Runway完成3.15亿美元E轮融资,Runway 完成 3.15 亿美元 E 轮，估值约 53 亿美元，资金指向下一代世界模型及产品扩展。,https://techcrunch.com/2026/02/10/ai-video-startup-runway-raises-315m-at-5-3b-valuation-eyes-more-capable-world-models,primary,candidate,2026-02-12,Runway 完成 3.15 亿美元 E 轮，估值约 53 亿美元，资金指向下一代世界模型及产品扩展。,data/raw/wechat/2026-02-11.md,19,from_ai_daily_primary_link
C00060,cmp_nebius,Nebius,daily_report_fact,text,Nebius收购Tavily,2026-02-11,Nebius收购Tavily,Nebius 宣布收购 agentic search 提供商 Tavily，目标增强 AI 云平台的实时网络验证能力。,https://nebius.com/newsroom/nebius-announces-agreement-to-acquire-tavily-to-add-agentic-search-to-its-ai-cloud-platform,primary,candidate,2026-02-12,Nebius 宣布收购 agentic search 提供商 Tavily，目标增强 AI 云平台的实时网络验证能力。,data/raw/wechat/2026-02-11.md,20,from_ai_daily_primary_link
C00061,cmp_tavily,Tavily,daily_report_fact,text,Nebius收购Tavily,2026-02-11,Nebius收购Tavily,Nebius 宣布收购 agentic search 提供商 Tavily，目标增强 AI 云平台的实时网络验证能力。,https://nebius.com/newsroom/nebius-announces-agreement-to-acquire-tavily-to-add-agentic-search-to-its-ai-cloud-platform,primary,candidate,2026-02-12,Nebius 宣布收购 agentic search 提供商 Tavily，目标增强 AI 云平台的实时网络验证能力。,data/raw/wechat/2026-02-11.md,20,from_ai_daily_primary_link
C00062,cmp_anthropic,Anthropic,daily_report_fact,text,Anthropic发布2026 Agent编程趋势报告,2026-02-11,Anthropic发布2026 Agent编程趋势报告,发布《2026 Agentic Coding Trends Report》，给出 Agent 编程趋势判断与角色迁移预测。,https://resources.anthropic.com/hubfs/2026%20Agentic%20Coding%20Trends%20Report.pdf?hsLang=en,primary,candidate,2026-02-12,发布《2026 Agentic Coding Trends Report》，给出 Agent 编程趋势判断与角色迁移预测。,data/raw/wechat/2026-02-11.md,21,from_ai_daily_primary_link
C00063,cmp_unsloth,Unsloth,daily_report_fact,text,Unsloth发布MoE训练优化,2026-02-11,Unsloth发布MoE训练优化,Unsloth 更新 MoE 训练优化，提到训练速度、显存节省与上下文扩展等指标。,https://unsloth.ai/docs/new/faster-moe,primary,candidate,2026-02-12,Unsloth 更新 MoE 训练优化，提到训练速度、显存节省与上下文扩展等指标。,data/raw/wechat/2026-02-11.md,22,from_ai_daily_primary_link
C00064,cpt_webmcp,WebMCP,daily_report_fact,text,Chrome 146 推出 WebMCP 早期预览,2026-02-11,Chrome 146 推出 WebMCP 早期预览,Chrome 146 引入 WebMCP 预览，允许 Agent 直接调用网站声明能力（实验状态，需启用 flag）。,https://docs.google.com/document/d/1rtU1fRPS0bMqd9abMG_hc6K9OAI6soUy3Kh00toAgyk/edit,primary,candidate,2026-02-12,Chrome 146 引入 WebMCP 预览，允许 Agent 直接调用网站声明能力（实验状态，需启用 flag）。,data/raw/wechat/2026-02-11.md,23,from_ai_daily_primary_link
C00065,cpt_glm-5,GLM-5,daily_report_fact,text,智谱AI发布并开源GLM-5模型,2026-02-12,智谱AI发布并开源GLM-5模型,智谱发布并开源 GLM-5（744B/激活40B），支持 200K 上下文，强调 coding 与 agent 能力，称在 SWE-bench-Verified 与 Terminal Bench 2.0 取得开源模型领先成绩，并已在官方产品线开放使用。,https://z.ai/blog/glm-5,primary,candidate,2026-02-12,智谱发布并开源 GLM-5（744B/激活40B），支持 200K 上下文，强调 coding 与 agent 能力，称在 SWE-bench-Verified 与 Terminal Bench 2.0 取得开源模型领先成绩，并已在官方产品线开放使用。,data/raw/wechat/2026-02-12.md,1,from_ai_daily_primary_link
C00066,,MiniMax,daily_report_fact,text,MiniMax上线MiniMax M2.5,2026-02-12,MiniMax上线MiniMax M2.5,MiniMax 上线新旗舰模型 MiniMax M2.5，可在 Web 端和桌面端 MiniMax Agent 调用。,https://agent.minimax.io/,primary,candidate,2026-02-12,MiniMax 上线新旗舰模型 MiniMax M2.5，可在 Web 端和桌面端 MiniMax Agent 调用。,data/raw/wechat/2026-02-12.md,3,from_ai_daily_primary_link
C00067,,MiniMax M2.5,daily_report_fact,text,MiniMax上线MiniMax M2.5,2026-02-12,MiniMax上线MiniMax M2.5,MiniMax 上线新旗舰模型 MiniMax M2.5，可在 Web 端和桌面端 MiniMax Agent 调用。,https://agent.minimax.io/,primary,candidate,2026-02-12,MiniMax 上线新旗舰模型 MiniMax M2.5，可在 Web 端和桌面端 MiniMax Agent 调用。,data/raw/wechat/2026-02-12.md,3,from_ai_daily_primary_link
C00068,,Ming-flash-omni 2.0,daily_report_fact,text,蚂蚁集团发布全模态大模型Ming-flash-omni 2.0,2026-02-12,蚂蚁集团发布全模态大模型Ming-flash-omni 2.0,蚂蚁集团发布 Ming-flash-omni 2.0（Ling-2.0 架构），支持多模态认知、统一音频生成与图像处理，并开源发布。,https://huggingface.co/inclusionAI/Ming-flash-omni-2.0,primary,candidate,2026-02-12,蚂蚁集团发布 Ming-flash-omni 2.0（Ling-2.0 架构），支持多模态认知、统一音频生成与图像处理，并开源发布。,data/raw/wechat/2026-02-12.md,5,from_ai_daily_primary_link
C00069,,MiniCPM-SALA,daily_report_fact,text,OpenBMB发布MiniCPM-SALA百万上下文模型,2026-02-12,OpenBMB发布MiniCPM-SALA百万上下文模型,OpenBMB 开源 MiniCPM-SALA（9B），采用混合稀疏与线性注意力机制，支持 1M 上下文。,https://huggingface.co/openbmb/MiniCPM-SALA,primary,candidate,2026-02-12,OpenBMB 开源 MiniCPM-SALA（9B），采用混合稀疏与线性注意力机制，支持 1M 上下文。,data/raw/wechat/2026-02-12.md,7,from_ai_daily_primary_link
C00070,,OpenBMB,daily_report_fact,text,OpenBMB发布MiniCPM-SALA百万上下文模型,2026-02-12,OpenBMB发布MiniCPM-SALA百万上下文模型,OpenBMB 开源 MiniCPM-SALA（9B），采用混合稀疏与线性注意力机制，支持 1M 上下文。,https://huggingface.co/openbmb/MiniCPM-SALA,primary,candidate,2026-02-12,OpenBMB 开源 MiniCPM-SALA（9B），采用混合稀疏与线性注意力机制，支持 1M 上下文。,data/raw/wechat/2026-02-12.md,7,from_ai_daily_primary_link
C00071,,Nanbeige4.1-3B,daily_report_fact,text,BOSS直聘推出Nanbeige4.1-3B模型,2026-02-12,BOSS直聘推出Nanbeige4.1-3B模型,BOSS直聘 Nanbeige LLM Lab 开源 Nanbeige4.1-3B，强调推理、偏好对齐与 Agent 能力。,https://huggingface.co/Nanbeige/Nanbeige4.1-3B,primary,candidate,2026-02-12,BOSS直聘 Nanbeige LLM Lab 开源 Nanbeige4.1-3B，强调推理、偏好对齐与 Agent 能力。,data/raw/wechat/2026-02-12.md,8,from_ai_daily_primary_link
C00072,,Soul-AILab,daily_report_fact,text,Soul推出SoulX-Singer歌声合成模型,2026-02-12,Soul推出SoulX-Singer歌声合成模型,Soul-AILab 开源 SoulX-Singer，支持零样本歌声合成与多语言演唱。,https://arxiv.org/abs/2602.07803,primary,candidate,2026-02-12,Soul-AILab 开源 SoulX-Singer，支持零样本歌声合成与多语言演唱。,data/raw/wechat/2026-02-12.md,9,from_ai_daily_primary_link
C00073,,SoulX-Singer,daily_report_fact,text,Soul推出SoulX-Singer歌声合成模型,2026-02-12,Soul推出SoulX-Singer歌声合成模型,Soul-AILab 开源 SoulX-Singer，支持零样本歌声合成与多语言演唱。,https://arxiv.org/abs/2602.07803,primary,candidate,2026-02-12,Soul-AILab 开源 SoulX-Singer，支持零样本歌声合成与多语言演唱。,data/raw/wechat/2026-02-12.md,9,from_ai_daily_primary_link
C00074,,Z Code,daily_report_fact,text,智谱正式发布AI编程工具 Z Code,2026-02-12,智谱正式发布AI编程工具 Z Code,智谱正式发布 Z Code，支持多 Agent 切换、内置浏览器、手机远程控制。,https://zcode-ai.com/,primary,candidate,2026-02-12,智谱正式发布 Z Code，支持多 Agent 切换、内置浏览器、手机远程控制。,data/raw/wechat/2026-02-12.md,10,from_ai_daily_primary_link
C00075,,Droid Agent,daily_report_fact,text,Factory与JetBrains合作集成Droid Agent,2026-02-12,Factory与JetBrains合作集成Droid Agent,Factory 与 JetBrains 合作，Droid 可在 JetBrains IDE 通过 ACP 运行。,https://docs.google.com/forms/d/e/1FAIpQLSdCLNQ_0uPgRwOu7L4vhkPYhznK1cO7M5FyvrCOXUzOCkjabw/viewform,primary,candidate,2026-02-12,Factory 与 JetBrains 合作，Droid 可在 JetBrains IDE 通过 ACP 运行。,data/raw/wechat/2026-02-12.md,13,from_ai_daily_primary_link
C00076,,Factory,daily_report_fact,text,Factory与JetBrains合作集成Droid Agent,2026-02-12,Factory与JetBrains合作集成Droid Agent,Factory 与 JetBrains 合作，Droid 可在 JetBrains IDE 通过 ACP 运行。,https://docs.google.com/forms/d/e/1FAIpQLSdCLNQ_0uPgRwOu7L4vhkPYhznK1cO7M5FyvrCOXUzOCkjabw/viewform,primary,candidate,2026-02-12,Factory 与 JetBrains 合作，Droid 可在 JetBrains IDE 通过 ACP 运行。,data/raw/wechat/2026-02-12.md,13,from_ai_daily_primary_link
C00077,,JetBrains,daily_report_fact,text,Factory与JetBrains合作集成Droid Agent,2026-02-12,Factory与JetBrains合作集成Droid Agent,Factory 与 JetBrains 合作，Droid 可在 JetBrains IDE 通过 ACP 运行。,https://docs.google.com/forms/d/e/1FAIpQLSdCLNQ_0uPgRwOu7L4vhkPYhznK1cO7M5FyvrCOXUzOCkjabw/viewform,primary,candidate,2026-02-12,Factory 与 JetBrains 合作，Droid 可在 JetBrains IDE 通过 ACP 运行。,data/raw/wechat/2026-02-12.md,13,from_ai_daily_primary_link
C00078,,GLM in Excel,daily_report_fact,text,智谱发布GLM in Excel插件,2026-02-12,智谱发布GLM in Excel插件,智谱发布 GLM in Excel (Beta)，通过侧边栏在 Excel 中执行数据分析、图表与公式修复等任务。,https://docs.bigmodel.cn/cn/guide/tools/glm-in-excel,primary,candidate,2026-02-12,智谱发布 GLM in Excel (Beta)，通过侧边栏在 Excel 中执行数据分析、图表与公式修复等任务。,data/raw/wechat/2026-02-12.md,15,from_ai_daily_primary_link
C00079,,Mistral AI,daily_report_fact,text,Mistral AI投资12亿欧元瑞典数据中心,2026-02-12,Mistral AI投资12亿欧元瑞典数据中心,Mistral AI 宣布在瑞典投资建设数据中心，计划 2027 年启用。,https://www.reuters.com/sustainability/boards-policy-regulation/france-ai-company-mistral-invests-14-billion-data-centres-sweden-2026-02-11/,primary,candidate,2026-02-12,Mistral AI 宣布在瑞典投资建设数据中心，计划 2027 年启用。,data/raw/wechat/2026-02-12.md,18,from_ai_daily_primary_link
C00080,cmp_openai,OpenAI,daily_report_fact,text,OpenAI解散任务对齐团队,2026-02-12,OpenAI解散任务对齐团队,OpenAI 解散任务对齐团队并调整组织架构，团队成员转至其他岗位。,https://openaiglobalaffairs.substack.com/p/introducing-our-chief-futurist,primary,candidate,2026-02-12,OpenAI 解散任务对齐团队并调整组织架构，团队成员转至其他岗位。,data/raw/wechat/2026-02-12.md,19,from_ai_daily_primary_link
C00081,cmp_xai,xAI,daily_report_fact,text,xAI进行重组与人事变动,2026-02-12,xAI进行重组与人事变动,xAI 重组为四个产品团队（Grok、编码系统、Imagine、Macrohard），伴随人员流动。,https://techcrunch.com/2026/02/11/xai-lays-out-interplanetary-ambitions-in-public-all-hands,primary,candidate,2026-02-12,xAI 重组为四个产品团队（Grok、编码系统、Imagine、Macrohard），伴随人员流动。,data/raw/wechat/2026-02-12.md,20,from_ai_daily_primary_link
C00082,,Prime Intellect,daily_report_fact,text,Prime Intellect推出全栈agentic训练平台,2026-02-12,Prime Intellect推出全栈agentic训练平台,Prime Intellect 推出 Lab，覆盖 agentic post-training 的训练、评估与环境管理。,https://www.primeintellect.ai/blog/lab,primary,candidate,2026-02-12,Prime Intellect 推出 Lab，覆盖 agentic post-training 的训练、评估与环境管理。,data/raw/wechat/2026-02-12.md,21,from_ai_daily_primary_link
C00083,,Gemini Deep Think,daily_report_fact,text,Gemini Deep Think 攻克科研级难题,2026-02-12,Gemini Deep Think 攻克科研级难题,Google DeepMind 与 Google Research 发布 Gemini Deep Think 相关论文，展示数学/物理/计算机科学研究应用。,https://deepmind.google/blog/accelerating-mathematical-and-scientific-discovery-with-gemini-deep-think/,primary,candidate,2026-02-12,Google DeepMind 与 Google Research 发布 Gemini Deep Think 相关论文，展示数学/物理/计算机科学研究应用。,data/raw/wechat/2026-02-12.md,22,from_ai_daily_primary_link
C00084,cmp_google,Google,daily_report_fact,text,Gemini Deep Think 攻克科研级难题,2026-02-12,Gemini Deep Think 攻克科研级难题,Google DeepMind 与 Google Research 发布 Gemini Deep Think 相关论文，展示数学/物理/计算机科学研究应用。,https://deepmind.google/blog/accelerating-mathematical-and-scientific-discovery-with-gemini-deep-think/,primary,candidate,2026-02-12,Google DeepMind 与 Google Research 发布 Gemini Deep Think 相关论文，展示数学/物理/计算机科学研究应用。,data/raw/wechat/2026-02-12.md,22,from_ai_daily_primary_link
C00085,,Andrej Karpathy,daily_report_fact,text,Karpathy开源243行纯 Python GPT 实现,2026-02-12,Karpathy开源243行纯 Python GPT 实现,Andrej Karpathy 发布 243 行纯 Python GPT 实现，用于展示最简核心算法。,https://gist.github.com/karpathy/8627fe009c40f57531cb18360106ce95,primary,candidate,2026-02-12,Andrej Karpathy 发布 243 行纯 Python GPT 实现，用于展示最简核心算法。,data/raw/wechat/2026-02-12.md,23,from_ai_daily_primary_link
C00086,cmp_anthropic,Anthropic,daily_report_fact,text,Anthropic发布Claude Opus 4.6破坏风险报告,2026-02-12,Anthropic发布Claude Opus 4.6破坏风险报告,Anthropic 发布 Claude Opus 4.6 sabotage risk report，结论为“非常低但不可忽略”。,https://anthropic.com/claude-opus-4-6-risk-report,primary,candidate,2026-02-12,Anthropic 发布 Claude Opus 4.6 sabotage risk report，结论为“非常低但不可忽略”。,data/raw/wechat/2026-02-12.md,24,from_ai_daily_primary_link
C00087,cpt_claude-opus-4-6,Claude Opus 4.6,daily_report_fact,text,Anthropic发布Claude Opus 4.6破坏风险报告,2026-02-12,Anthropic发布Claude Opus 4.6破坏风险报告,Anthropic 发布 Claude Opus 4.6 sabotage risk report，结论为“非常低但不可忽略”。,https://anthropic.com/claude-opus-4-6-risk-report,primary,candidate,2026-02-12,Anthropic 发布 Claude Opus 4.6 sabotage risk report，结论为“非常低但不可忽略”。,data/raw/wechat/2026-02-12.md,24,from_ai_daily_primary_link
C00088,,Codex Alpha,daily_report_fact,text,OpenAI开放Windows版Codex Alpha候补,2026-02-12,OpenAI开放Windows版Codex Alpha候补,OpenAI 开放 Codex Alpha Windows 版候补申请，Linux 版在计划中。,https://openai.com/form/codex-app/,primary,candidate,2026-02-12,OpenAI 开放 Codex Alpha Windows 版候补申请，Linux 版在计划中。,data/raw/wechat/2026-02-12.md,25,from_ai_daily_primary_link
C00089,cmp_openai,OpenAI,daily_report_fact,text,OpenAI开放Windows版Codex Alpha候补,2026-02-12,OpenAI开放Windows版Codex Alpha候补,OpenAI 开放 Codex Alpha Windows 版候补申请，Linux 版在计划中。,https://openai.com/form/codex-app/,primary,candidate,2026-02-12,OpenAI 开放 Codex Alpha Windows 版候补申请，Linux 版在计划中。,data/raw/wechat/2026-02-12.md,25,from_ai_daily_primary_link
